# DAG 실행 파라미터 표준화 설계 (v1.0)

**문서 목적**: 데이터 파이프라인의 모든 DAG에서 테스트 및 디버깅 목적의 실행 범위를 제어하기 위한 일관되고, 견고하며, 유연한 표준 방법론을 정의한다.

---

## 1. 문제 정의

기존의 테스트 파라미터 방식은 아래와 같은 문제점을 가지고 있었다.

- **비일관성**: `stock_limit`(개수 제한), `target_stock_codes`(목록 지정) 등 여러 방식이 혼재하여 DAG마다 사용법이 달랐다.
- **오류 취약성**: 사용자의 직접 입력(종목 코드)에 의존하여 오타, 공백 등으로 인한 오류 발생 가능성이 높았다.
- **재현성 부재**: 어떤 파라미터로 테스트를 실행했는지에 대한 명확한 기록이 남지 않아, 문제 발생 시 원인 추적 및 재현이 어려웠다.
- **유연성 부족**: "특정 종목 N개" 방식은 정교한 테스트 케이스(예: 특정 오류를 유발하는 종목들)를 구성하기 어려웠다.

## 2. 설계 원칙

새로운 파라미터 표준은 다음 원칙을 만족해야 한다.

- **일관성 (Consistency)**: 모든 DAG는 동일한 메커니즘을 통해 실행 범위를 제어해야 한다.
- **명확성 (Clarity)**: 테스트 실행의 의도와 범위가 파라미터를 통해 명확하게 표현되어야 한다.
- **유연성 (Flexibility)**: 정형화된 시나리오 테스트와 즉흥적인 단일 종목 디버깅을 모두 지원해야 한다.
- **견고성 (Robustness)**: 잘못된 사용자 입력이 파이프라인 전체의 실패로 이어지지 않도록, 시스템이 스스로 방어하고 명확한 피드백을 제공해야 한다.

## 3. 최종 설계: 하이브리드 파라미터 모델

위 원칙들을 모두 만족하기 위해, **두 종류의 파라미터를 조합한 하이브리드 모델**을 최종 설계로 채택한다.

### 3.1. 파라미터 정의

각 DAG는 아래 두 개의 표준 파라미터를 갖는다.

1.  **`target_stock_codes` (String)**: **즉시 오버라이드(Override)용**
    - **목적**: 특정 종목 한두 개에 대한 빠른 디버깅 및 즉흥적인 테스트를 위함.
    - **형식**: 쉼표(`,`)로 구분된 종목 코드 문자열. (예: `"005930,000660"`)
    - **동작**: 이 파라미터에 값이 있으면, 다른 모든 조건을 무시하고 항상 최우선으로 적용된다.

2.  **`test_scenario` (String, Enum)**: **표준 시나리오 선택용**
    - **목적**: 자주 사용하거나 의미 있는 종목들의 묶음을 사전 정의하여, 쉽고 반복 가능한 표준 테스트를 위함.
    - **형식**: 사전 정의된 시나리오 이름. (예: `"major_banks"`)
    - **동작**: `target_stock_codes`가 비어 있을 때 적용된다.

### 3.2. 실행 우선순위

분석 대상 종목을 결정하는 로직은 아래의 명확한 우선순위를 따른다.

1.  **1순위**: `target_stock_codes` 파라미터가 존재하는가?
    - **Yes**: 해당 종목 리스트를 사용. (즉시 테스트 모드)
2.  **2순위**: `test_scenario` 파라미터가 선택되었는가?
    - **Yes**: `test_scenarios.json` 파일에서 해당 시나리오의 종목 리스트를 읽어서 사용. (시나리오 테스트 모드)
3.  **3순위**: 위 두 파라미터가 모두 비어있는가?
    - **Yes**: DB에서 `is_analysis_target=True`인 모든 종목을 조회하여 사용. (기본 운영 모드)

### 3.3. `test_scenarios.json` 파일 명세

- **위치**: `DataPipeline/data/test_scenarios.json`
- **역할**: 표준 테스트 시나리오들을 중앙에서 관리하는 파일. 버전 관리 시스템(Git)에 포함되어 변경 이력을 추적한다.
- **구조**:
  ```json
  {
    "description": "DAG 테스트를 위한 표준 시나리오 모음",
    "scenarios": {
      "samsung_and_hynix": {
        "description": "삼성전자, SK하이닉스 기본 테스트",
        "codes": ["005930", "000660"]
      },
      "major_banks": {
        "description": "주요 은행주 4개",
        "codes": ["105560", "055550", "323410", "000020"]
      },
      "past_error_cases": {
        "description": "과거 RS 계산 등에서 오류가 발생했던 종목들",
        "codes": ["000150", "123456"]
      },
      "empty_case": {
        "description": "대상이 없을 때의 동작을 테스트하기 위한 빈 시나리오",
        "codes": []
      }
    }
  }
  ```

### 3.4. 표준 로직 구현 (모듈화)

- **위치**: `DataPipeline/src/utils/dag_helpers.py` (신규 생성 또는 기존 유틸 파일 활용)
- **역할**: 위에서 정의한 우선순위, 입력값 처리, 유효성 검증, 로깅 등 표준 로직 전체를 포함하는 단일 함수를 구현하여 코드 중복을 방지하고 유지보수성을 극대화한다.

- **함수 시그니처 예시**:
  ```python
  # in DataPipeline/src/utils/dag_helpers.py
  from typing import List
  
  def get_execution_target_codes(**kwargs) -> List[str]:
      """
      DAG의 런타임 파라미터를 해석하여, 이번 실행에서 처리할 최종 종목 코드 리스트를 반환한다.
      하이브리드 모델의 우선순위(target_stock_codes > test_scenario > default)를 따른다.
      """
      # 1. 컨텍스트에서 파라미터 추출 및 로깅
      # 2. 1순위: target_stock_codes 처리 (문자열 파싱, 정제, DB 존재 여부 검증)
      # 3. 2순위: test_scenario 처리 (JSON 파일 로드, 시나리오 존재 여부 검증)
      # 4. 3순위: 기본 운영 모드 처리 (DB에서 is_analysis_target=True 조회)
      # 5. 최종 결정된 종목 리스트와 실행 모드를 로그로 명확히 기록 후 반환
      pass
  ```

## 4. 기대 효과

- **개발 생산성 향상**: 모든 DAG에서 일관된 방식으로 빠르고 유연한 테스트가 가능해진다.
- **테스트 신뢰도 향상**: 표준화된 시나리오를 통해 체계적인 회귀 테스트가 가능해진다.
- **명확한 감사 및 재현성**: 실행 로그만으로 어떤 데이터 범위로 테스트했는지 명확히 추적할 수 있다.
- **유지보수성 극대화**: 테스트 관련 로직이 중앙 유틸리티 함수로 모듈화되어 관리가 용이해진다.
