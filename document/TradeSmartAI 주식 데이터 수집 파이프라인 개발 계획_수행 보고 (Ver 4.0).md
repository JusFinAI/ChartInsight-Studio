### **TradeSmartAI 주식 데이터 수집 파이프라인 개발 계획/수행 보고 (Ver 4.0)**

* **버전:** 4.0  
* **작성일:** 2025년 7월 20일  
* **작성자:** Gemini AI (코칭 및 문서화 지원)

### **1\. 프로젝트 개요**

"TradeSmartAI" 웹 서비스의 핵심 기반이 될 주식 데이터 수집 파이프라인을 구축하는 것을 목표로 한다. 키움증권 REST API를 통해 국내 주식 종목들의 OHLCV 데이터를 수집하고, PostgreSQL 데이터베이스에 저장하며, Apache Airflow로 전체 프로세스를 자동화한다.

* **궁극적 목표:**  
  * 안정적이고 신뢰할 수 있는 주식 데이터 저장소 구축.  
  * 자동화된 데이터 수집 및 DB 업데이트 프로세스 확립.  
  * 향후 AI 기능 개발을 위한 견고한 데이터 기반 마련.

---

### **2\. 기술 스택**

* **오케스트레이션:** Apache Airflow (Docker Compose 기반 로컬 환경)  
* **데이터베이스:** PostgreSQL (Docker 컨테이너)  
* **데이터 수집:** 키움증권 REST API  
* **개발 언어:** Python 3.x  
* **환경:** Docker Desktop with WSL2

---

### **3\. 단계별 계획 및 수행 보고**

### **3.1  1단계 개발 완료: 주요 성과 및 확립된 기술 원칙**

1단계 로컬 개발 및 검증 단계가 성공적으로 완료되었다. 이 과정에서 단순 기능 구현을 넘어, 실제 운영 환경에서 발생할 수 있는 다양한 문제들을 해결하며 다음과 같은 핵심 기술 원칙을 확립했다.

#### **3.1.1  통합 개발 환경 안정화 및 기반 구축**

* **Docker 기반의 안정적인 개발 환경 구축:** docker-compose.yaml을 통해 Airflow와 PostgreSQL 서비스가 분리된 안정적인 로컬 개발 환경을 구축하고 검증했다. 1파일 권한(UID/GID), 모듈 경로(PYTHONPATH), 서비스 초기화(  
* airflow-init) 등 복잡한 인프라 문제를 모두 해결하여 재현 가능한 개발 환경을 마련했다. 2  
* **프로토타입 개발 및 핵심 로직 검증:** data\_collector\_test.py 및 테스트용 DAG를 통해 단일 종목에 대한 데이터 수집-저장-자동화의 전체 흐름을 성공적으로 구현하고, 종목 정보 자동 적재 로직을 DAG에 통합하여 파이프라인의 기본 골격을 완성했다. 3  
* **전체 파이프라인 아키텍처 설계 완료:** 프로토타입 개발 경험을 바탕으로, initial(초기 적재)과 incremental(증분 업데이트) 기능이 분리되고, 로컬 CLI와 Airflow 환경 모두에서 동작하는 '컨텍스트 인지형' 아키텍처를 PRD Ver 4.0로 최종 설계했다. 4

#### **3.1.2 아키텍처 고도화 및 운영 안정성 확보**

* **데이터베이스 스키마 분리 (live vs. simulation):** 운영 데이터와 시뮬레이션 데이터의 격리를 통해 테스트 안정성을 극대화하고 운영 환경을 보호하는 아키텍처를 도입했다. database.py의 init\_db 함수에 스키마 자동 생성 로직을 추가하여 이 과정을 자동화했다.  
* **동적 DAG 생성 패턴 도입:** 5개의 개별 증분 업데이트 DAG 파일을 dag\_live\_collectors.py 단일 파일로 통합하여, 코드 중복을 제거하고 유지보수성을 극대화하는 전문가적인 설계 패턴을 적용했다.  
* **Airflow Pool을 이용한 API 호출 제어:** kiwoom\_api\_pool을 생성 및 적용하여, 다수의 Task가 동시에 실행되더라도 실제 API 호출은 순차적으로 이루어지도록 제어함으로써 API Rate Limit 초과 위험을 원천 차단했다.  
* **Airflow Variable을 이용한 DAG 워크플로우 자동화:** dag\_initial\_loader가 실행된 후, Variable.set()을 통해 dag\_simulation\_tester의 실행 파라미터를 자동으로 설정하는 로직을 추가하여, 수동 개입 없는 매끄러운 테스트 워크플로우를 구축했다.  
* **(기타 주요 문제 해결):** 외래 키(Foreign Key) 경로 명시, docker-compose.yaml의 로그 서버 주소 설정 등 실제 운영에서 발생할 수 있는 다수의 기술적 문제를 해결하며 시스템의 안정성을 크게 높였다.

**3.2. 2단계: 전체 파이프라인 확장 및 안정화 (진행 중)**

**목표:** 1단계에서 검증된 아키텍처를 바탕으로, 30개 전체 타겟 종목에 대한 데이터 적재를 완료하고, 자동화된 증분 업데이트 파이프라인을 안정적으로 운영 궤도에 올린다.

**핵심 활동:**

1. **Live 모드 초기 데이터 적재 완료:**  
   * dag\_initial\_loader를 LIVE 모드로 실행하여, 30개 전체 타겟 종목의 모든 타임프레임에 대한 과거 데이터를 live.candles 테이블에 적재한다.  
   2. **운영용 증분 업데이트 DAG 활성화 및 모니터링:**  
      * dag\_live\_collectors.py에 의해 동적으로 생성된 5개의 운영용 DAG를 모두 활성화한다.  
      * 며칠간 DAG들이 스케줄에 맞춰 정상적으로 실행되고, live.candles 테이블에 최신 데이터가 누락 없이 쌓이는지 집중적으로 모니터링한다.  
   3. **(선택) 모니터링 및 알림 강화:**  
      * DAG 실행 실패 시, 담당자에게 Email 또는 Slack으로 즉시 알림을 보내는 기능을 추가하여 장애 발생 시 빠른 대응이 가능하도록 시스템을 고도화한다.

#### **3.3. 3단계: GCP 시험 운영 (계획)**

* **목표:** 로컬에서 완벽하게 검증된 주식 데이터 수집 파이프라인을 Google Cloud Platform (GCP) 환경에 배포하고, 실제 클라우드 환경에서 24시간 안정적으로 데이터가 수집 및 업데이트되는지 확인한다.  
* **핵심 활동:**  
  * **인프라 구축:** Compute Engine(Airflow 호스팅), Cloud SQL(PostgreSQL 호스팅) 등 GCP 리소스 생성 및 네트워크 설정.  
  * **파이프라인 배포:** 로컬의 프로젝트 코드를 Compute Engine으로 이전하고, .env 파일을 GCP 환경에 맞게 수정.  
  * **시스템 구동 및 모니터링:** docker-compose를 통해 GCP에서 Airflow 서비스를 실행하고, Cloud Logging 및 Cloud Monitoring을 통해 파이프라인 상태를 실시간으로 감시.  
  * **비용 최적화:** GCP 서비스 비용을 주기적으로 모니터링하고 리소스를 최적화.