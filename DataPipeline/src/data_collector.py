"""
TradeSmartAI ë°ì´í„° ìˆ˜ì§‘ í•µì‹¬ ì—”ì§„

ì´ ëª¨ë“ˆì€ TradeSmartAI í”„ë¡œì íŠ¸ì˜ ë°ì´í„° ìˆ˜ì§‘ í•µì‹¬ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
Apache Airflow DAG í™˜ê²½ê³¼ ë¡œì»¬ CLI í™˜ê²½ ëª¨ë‘ì—ì„œ ë™ì‘í•˜ë©°,
LIVE ëª¨ë“œ(í‚¤ì›€ API)ì™€ SIMULATION ëª¨ë“œ(Parquet íŒŒì¼)ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- load_initial_history: ê³¼ê±° ë°ì´í„° ëŒ€ëŸ‰ ì ì¬
- collect_and_store_candles: ìµœì‹  ë°ì´í„° ì¦ë¶„ ìˆ˜ì§‘ (ë©±ë“±ì„± ë³´ì¥)
- CLI ì¸í„°í˜ì´ìŠ¤: initial, incremental ì„œë¸Œì»¤ë§¨ë“œ
"""

import os
import sys
import argparse
import logging
import pandas as pd
import time
from datetime import datetime, timedelta
from typing import Optional, List, Tuple
from zoneinfo import ZoneInfo
from pathlib import Path
import re


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from src.database import SessionLocal, Candle, Stock
from src.kiwoom_api.services.chart import get_minute_chart, get_daily_chart, get_weekly_chart
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import Session

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜
TIMEFRAME_TO_MINUTES = {
    '5m': 5,
    '30m': 30,
    '1h': 60
}

TIMEFRAME_TO_DB_FORMAT = {
    '5m': 'M5', 
    '30m': 'M30',
    '1h': 'H1',
    'd': 'D',
    'w': 'W'
}

TIMEFRAME_TO_LABEL = {
    '5m': '5ë¶„',
    '30m': '30ë¶„', 
    '1h': '1ì‹œê°„',
    'd': 'ì¼',
    'w': 'ì£¼'
}

# íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™”ëœ ê¸°ë³¸ ê¸°ê°„ ë§¤í•‘
TIMEFRAME_DEFAULT_PERIODS = {
    '5m': '30d',    # 5ë¶„ë´‰: 30ì¼ (ì•½ 8,640ê°œ ìº”ë“¤)
    '30m': '6m',    # 30ë¶„ë´‰: 6ê°œì›” (ì•½ 8,760ê°œ ìº”ë“¤)
    '1h': '1y',     # 1ì‹œê°„ë´‰: 1ë…„ (ì•½ 8,760ê°œ ìº”ë“¤)
    'd': '5y',      # ì¼ë´‰: 5ë…„ (ì•½ 1,825ê°œ ìº”ë“¤)
    'w': '10y'      # ì£¼ë´‰: 10ë…„ (ì•½ 520ê°œ ìº”ë“¤)
}

def _db_upsert_candles(db: Session, stock_code: str, timeframe: str, df_candles: pd.DataFrame, execution_mode: str = 'LIVE') -> int:
    """
    DataFrame í˜•íƒœì˜ ìº”ë“¤ ë°ì´í„°ë¥¼ Candle í…Œì´ë¸”ì— UPSERT í•©ë‹ˆë‹¤.
    stock_code, timestamp, timeframe ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬ ë° ì‚½ì…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        db (Session): DB ì„¸ì…˜
        stock_code (str): ì¢…ëª© ì½”ë“œ
        timeframe (str): íƒ€ì„í”„ë ˆì„ (5m, 30m, 1h, d, w)
        df_candles (pd.DataFrame): ìº”ë“¤ ë°ì´í„° DataFrame
        
    Returns:
        int: ìƒˆë¡œ ì‚½ì…ëœ ìº”ë“¤ ë°ì´í„° ê°œìˆ˜
    """
    if df_candles is None or df_candles.empty:
        logger.info(f"[{stock_code}] DBì— ì €ì¥í•  ìº”ë“¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    # ëª¨ë“œì— ë”°ë¼ ì‚¬ìš©í•  ìŠ¤í‚¤ë§ˆë¥¼ ê²°ì •í•˜ê³  í…Œì´ë¸” ê°ì²´ì— ì ìš©í•©ë‹ˆë‹¤.
    target_schema = 'simulation' if execution_mode == 'SIMULATION' else 'live'
    Stock.__table__.schema = target_schema
    Candle.__table__.schema = target_schema
    logger.info(f"Target schema set to: {target_schema}")

    logger.info(f"[{stock_code}] {len(df_candles)}ê°œ ìº”ë“¤ ë°ì´í„° DB ì €ì¥ ì‹œì‘...")
    
    upserted_count = 0
    try:
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (ë°°ì¹˜ë¡œ í•œë²ˆì—)
        timeframe_str = TIMEFRAME_TO_DB_FORMAT.get(timeframe, timeframe)
        
        # DataFrameì—ì„œ timestamp ì¶”ì¶œ (data_collector_test.py ë°©ì‹ ì ìš©)
        timestamps = []
        for idx, row in df_candles.iterrows():
            if 'timestamp' in df_candles.columns:
                timestamp = row['timestamp']
            else:
                timestamp = idx  # DataFrame ì¸ë±ìŠ¤ ì‚¬ìš© (í‚¤ì›€ API ë°©ì‹)
            
            if not isinstance(timestamp, datetime):
                timestamp = pd.Timestamp(timestamp).to_pydatetime()
            
            timestamps.append(timestamp)
        
        # ê¸°ì¡´ ë°ì´í„° ë°°ì¹˜ ì¡°íšŒ
        existing_timestamps = set()
        if timestamps:
            existing_candles = db.query(Candle.timestamp).filter(
                Candle.stock_code == stock_code,
                Candle.timeframe == timeframe_str,
                Candle.timestamp.in_(timestamps)
            ).all()
            existing_timestamps = {candle.timestamp for candle in existing_candles}
            logger.info(f"[{stock_code}] ê¸°ì¡´ ë°ì´í„° {len(existing_timestamps)}ê°œ ë°œê²¬")
        
        # ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì‚½ì…
        new_candles = []
        for i, (idx, row) in enumerate(df_candles.iterrows()):
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (data_collector_test.py ë°©ì‹ ì ìš©)
            if 'timestamp' in df_candles.columns:
                timestamp = row['timestamp']
            else:
                timestamp = idx  # DataFrame ì¸ë±ìŠ¤ ì‚¬ìš© (í‚¤ì›€ API ë°©ì‹)
            
            if not isinstance(timestamp, datetime):
                timestamp = pd.Timestamp(timestamp).to_pydatetime()
            
            candle_timestamp = timestamp
            
            # timezone-naive íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ KSTë¡œ localize
            if candle_timestamp.tzinfo is None:
                candle_timestamp = candle_timestamp.replace(tzinfo=ZoneInfo('Asia/Seoul'))
            
            # KST tz-awareë¥¼ UTCë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµ
            candle_timestamp_utc = candle_timestamp.astimezone(ZoneInfo('UTC'))
            
            if candle_timestamp_utc not in existing_timestamps:
                # ì»¬ëŸ¼ëª… ë§¤í•‘ (í‚¤ì›€ API ì‘ë‹µ í˜•ì‹ ì§€ì›)
                open_val = (float(row['Open']) if 'Open' in row else 
                           float(row['open']) if 'open' in row else 
                           float(row['open_pric']) if 'open_pric' in row else None)
                
                high_val = (float(row['High']) if 'High' in row else 
                           float(row['high']) if 'high' in row else 
                           float(row['high_pric']) if 'high_pric' in row else None)
                
                low_val = (float(row['Low']) if 'Low' in row else 
                          float(row['low']) if 'low' in row else 
                          float(row['low_pric']) if 'low_pric' in row else None)
                
                close_val = (float(row['Close']) if 'Close' in row else 
                            float(row['close']) if 'close' in row else 
                            float(row['cur_prc']) if 'cur_prc' in row else None)
                
                volume_val = (int(row['Volume']) if 'Volume' in row else 
                             int(row['volume']) if 'volume' in row else 
                             int(row['trde_qty']) if 'trde_qty' in row else None)
                
                if None in [open_val, high_val, low_val, close_val, volume_val]:
                    logger.error(f"[{stock_code}] í•„ìˆ˜ ì»¬ëŸ¼ ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(row.index)}")
                    continue
                
                new_candle = Candle(
                    stock_code=stock_code,
                    timestamp=candle_timestamp,  # KST tz-aware ì €ì¥ (PostgreSQLì´ ìë™ìœ¼ë¡œ UTCë¡œ ì •ê·œí™”)
                    timeframe=timeframe_str,
                    open=open_val,
                    high=high_val,
                    low=low_val,
                    close=close_val,
                    volume=volume_val
                )
                new_candles.append(new_candle)
        
        # ë°°ì¹˜ ì‚½ì…
        if new_candles:
            db.add_all(new_candles)
            upserted_count = len(new_candles)
            logger.info(f"[{stock_code}] {upserted_count}ê°œ ì‹ ê·œ ìº”ë“¤ ë°ì´í„° ì‚½ì… ì¤‘...")
            db.commit()
            logger.info(f"[{stock_code}] {upserted_count}ê°œì˜ ì‹ ê·œ ìº”ë“¤ ë°ì´í„°ê°€ DBì— ì»¤ë°‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            logger.info(f"[{stock_code}] ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„° ì—†ìŒ.")
            
    except SQLAlchemyError as e:
        db.rollback()
        logger.error(f"[{stock_code}] DB ì €ì¥/ì»¤ë°‹ ì¤‘ SQLAlchemy ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise  
    except KeyError as e:
        db.rollback()
        logger.error(f"[{stock_code}] DataFrameì— í•„ìš”í•œ ì»¬ëŸ¼({e})ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df_candles.columns)}")
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"[{stock_code}] DB ì €ì¥ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
        
    return upserted_count

def _parse_period(period: str, timeframe: str) -> int:
    """
    ê¸°ê°„ ë¬¸ìì—´ê³¼ íƒ€ì„í”„ë ˆì„ì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì²­í•  ìº”ë“¤ ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        period (str): ê¸°ê°„ ë¬¸ìì—´ (ì˜ˆ: '30d', '6m', '2y', '10w') ë˜ëŠ” None
        timeframe (str): íƒ€ì„í”„ë ˆì„ (ì˜ˆ: '5m', '30m', '1h', 'd', 'w')
    
    Returns:
        int: ìš”ì²­í•  ìº”ë“¤ ê°œìˆ˜ (ìµœì†Œ 1ê°œ ë³´ì¥)
    
    Raises:
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„ì´ê±°ë‚˜ ì˜ëª»ëœ ê¸°ê°„ í˜•ì‹
        TypeError: periodê°€ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°
    
    Examples:
        >>> _parse_period('30d', '5m')
        2340  # 30ì¼ Ã— 78ê°œ/ì¼ = 2,340ê°œ
        >>> _parse_period('6m', '30m') 
        1638  # 6ê°œì›” Ã— 21ì¼/ì›” Ã— 13ê°œ/ì¼ = 1,638ê°œ
        >>> _parse_period('5y', 'd')
        1260  # 5ë…„ Ã— 252ì¼/ë…„ Ã— 1ê°œ/ì¼ = 1,260ê°œ
        >>> _parse_period(None, '5m')
        2340  # ê¸°ë³¸ê°’ 30d ì‚¬ìš©
    """
    # ì…ë ¥ ê²€ì¦
    if not isinstance(timeframe, str):
        raise TypeError(f"timeframeì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {type(timeframe)}")
    
    timeframe = timeframe.lower()
    
    # periodê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    if not period:
        period = TIMEFRAME_DEFAULT_PERIODS.get(timeframe, '1y')
        print(f"âš ï¸ periodê°€ ì§€ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ì‚¬ìš©: {timeframe} â†’ {period}")
    
    if not isinstance(period, str):
        raise TypeError(f"periodëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {type(period)}")
    
    period = period.lower().strip()
    total_days = 0

    # 1. ê¸°ê°„ ë¬¸ìì—´ì„ ì´ 'ê±°ë˜ì¼ ìˆ˜'ë¡œ ë³€í™˜
    try:
        if 'y' in period:
            match = re.search(r'(\d+)y', period)
            if not match:
                raise ValueError(f"ì˜ëª»ëœ ì—°ë„ í˜•ì‹: {period}")
            years = int(match.group(1))
            total_days = years * 252  # 1ë…„ = ì•½ 252 ê±°ë˜ì¼
            
        elif 'm' in period:
            match = re.search(r'(\d+)m', period)
            if not match:
                raise ValueError(f"ì˜ëª»ëœ ì›” í˜•ì‹: {period}")
            months = int(match.group(1))
            total_days = months * 21   # 1ê°œì›” = ì•½ 21 ê±°ë˜ì¼
            
        elif 'w' in period:
            match = re.search(r'(\d+)w', period)
            if not match:
                raise ValueError(f"ì˜ëª»ëœ ì£¼ í˜•ì‹: {period}")
            weeks = int(match.group(1))
            total_days = weeks * 5     # 1ì£¼ = 5 ê±°ë˜ì¼
            
        elif 'd' in period:
            match = re.search(r'(\d+)d', period)
            if not match:
                raise ValueError(f"ì˜ëª»ëœ ì¼ í˜•ì‹: {period}")
            days = int(match.group(1))
            total_days = days
            
        else:
            # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì¼ìˆ˜ë¡œ ì·¨ê¸‰
            total_days = int(period)
            
    except ValueError as e:
        raise ValueError(f"ì˜ëª»ëœ ê¸°ê°„ í˜•ì‹ '{period}': {str(e)}")
    except Exception as e:
        raise ValueError(f"ê¸°ê°„ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ '{period}': {str(e)}")

    # 2. ì£¼ë´‰(w)ì€ íŠ¹ë³„ ì²˜ë¦¬: ê±°ë˜ì¼ ìˆ˜ë¥¼ ì£¼ ìˆ˜ë¡œ ë³€í™˜
    if timeframe == 'w':
        # 1ì£¼ëŠ” 5ê±°ë˜ì¼ì´ë¯€ë¡œ, ì´ ê±°ë˜ì¼ì„ 5ë¡œ ë‚˜ëˆˆ ê°’ì´ ì£¼ë´‰ ìº”ë“¤ ìˆ˜
        return max(1, total_days // 5)

    # 3. íƒ€ì„í”„ë ˆì„ë³„ í•˜ë£¨ë‹¹ ìº”ë“¤ ìˆ˜ ì •ì˜ (í•œêµ­ ì£¼ì‹ì‹œì¥ ê¸°ì¤€)
    candles_per_day = {
        '5m': 78,   # (6ì‹œê°„ 30ë¶„ * 60ë¶„) / 5ë¶„ = 78ê°œ
        '30m': 13,  # (6.5ì‹œê°„ * 60) / 30ë¶„ = 13ê°œ
        '1h': 7,    # (6.5ì‹œê°„ * 60) / 60ë¶„ = 6.5ê°œ â†’ ì˜¬ë¦¼ ì²˜ë¦¬
        'd': 1,     # ì¼ë´‰ì€ í•˜ë£¨ì— 1ê°œ
    }
    
    if timeframe not in candles_per_day:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {timeframe}")

    # 4. ìµœì¢… ìº”ë“¤ ìˆ˜ ê³„ì‚°: (ì´ ê±°ë˜ì¼ ìˆ˜) * (í•˜ë£¨ë‹¹ ìº”ë“¤ ìˆ˜)
    total_candles = total_days * candles_per_day[timeframe]
    
    # 5. ìµœì†Œê°’ ë³´ì¥ ë° ê²°ê³¼ ë°˜í™˜
    result = max(1, int(total_candles))
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ (ì„ íƒì‚¬í•­)
    print(f" ê¸°ê°„ ê³„ì‚°: {period} ({timeframe}) â†’ {total_days}ì¼ â†’ {result}ê°œ ìº”ë“¤")
    
    return result

def _calculate_start_date(end_date: str, period: str) -> str:
    """
    ì¢…ë£Œì¼ê³¼ ê¸°ê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘ì¼ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        end_date (str): ì¢…ë£Œì¼ (YYYYMMDD)
        period (str): ê¸°ê°„ ë¬¸ìì—´ (ì˜ˆ: '2y', '6m', '30d')
        
    Returns:
        str: ì‹œì‘ì¼ (YYYYMMDD)
    """
    days = _parse_period(period, 'd') # ì¼ë´‰ ê¸°ì¤€ìœ¼ë¡œ íŒŒì‹±
    end_date_obj = datetime.strptime(end_date, '%Y%m%d')
    
    # ê±°ë˜ì¼ì„ ë‹¬ë ¥ì¼ë¡œ ë³€í™˜ (ì£¼ë§ ê³ ë ¤)
    calendar_days = int(days * 1.4)
    start_date_obj = end_date_obj - timedelta(days=calendar_days)
    
    return start_date_obj.strftime('%Y%m%d')

def _load_simulation_data(stock_code: str, timeframe: str, execution_time: str = None) -> pd.DataFrame:
    """
    ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œ Parquet íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    prepare_test_data.pyì—ì„œ ìƒì„±í•œ íŒŒì¼ í˜•ì‹ì— ë§ì¶° íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        stock_code (str): ì¢…ëª© ì½”ë“œ
        timeframe (str): íƒ€ì„í”„ë ˆì„ (5m, 30m, 1h, d, w)
        execution_time (str, optional): ì‹¤í–‰ ì‹œê°„ (YYYYMMDDHHMMSS)
        
    Returns:
        pd.DataFrame: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì„œìš¸ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ë¨)
    """
    # ì˜¬ë°”ë¥¸ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    simulation_data_dir = Path("data/simulation")
    
    # prepare_test_data.pyì—ì„œ ìƒì„±í•œ íŒŒì¼ëª… íŒ¨í„´: {stock_code}_{timeframe}_full.parquet
    # timeframe ë³€ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë§¤í•‘ ë¡œì§ ì œê±°)
    parquet_file = simulation_data_dir / f"{stock_code}_{timeframe}_full.parquet"
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not parquet_file.exists():
        logger.warning(f"ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {parquet_file}")
        return pd.DataFrame()
    
    try:
        df = pd.read_parquet(parquet_file)
        logger.info(f"ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼ ë¡œë“œ: {parquet_file.name}, ì›ë³¸ ë°ì´í„°: {len(df)}ê°œ")
        
        # ğŸ”¥ íƒ€ì„ì¡´ ë³€í™˜: "ì €ì¥ì€ UTC, ì‚¬ìš©ì€ ë¡œì»¬ íƒ€ì„ì¡´" í™©ê¸ˆë¥  ì ìš©
        if hasattr(df.index, 'tz'):
            # íƒ€ì„ì¡´ ì²˜ë¦¬ (PostgreSQLê³¼ ë™ì¼í•œ ì›ì¹™)
            if df.index.tz is None:
                # ê¸°ì¡´ íŒŒì¼ í˜¸í™˜ì„±: naiveë¥¼ UTCë¡œ ê°€ì •
                df.index = df.index.tz_localize('UTC')
                logger.info("íƒ€ì„ì¡´ ë³€í™˜: Timezone-naive â†’ UTC (ê¸°ì¡´ íŒŒì¼ í˜¸í™˜ì„±)")
            
            # UTC â†’ Asia/Seoulë¡œ ë³€í™˜ (PostgreSQLê³¼ ë™ì¼)
            df.index = df.index.tz_convert(ZoneInfo('Asia/Seoul'))
            logger.info("íƒ€ì„ì¡´ ë³€í™˜: UTC â†’ Asia/Seoul")
        else:
            logger.warning("DataFrame ì¸ë±ìŠ¤ê°€ datetimeì´ ì•„ë‹™ë‹ˆë‹¤. íƒ€ì„ì¡´ ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        # execution_timeì´ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ì‹œê°„ê¹Œì§€ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
        # ì´ê²ƒì´ í•µì‹¬: ì‹œë®¬ë ˆì´ì…˜ì—ì„œ "í˜„ì¬ ì‹œê°„"ê¹Œì§€ì˜ ë°ì´í„°ë§Œ ë³´ì—¬ì¤Œ
        if execution_time:
            execution_dt = pd.to_datetime(execution_time, format='%Y%m%d%H%M%S')
            # execution_dtë¥¼ ì„œìš¸ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
            execution_dt = execution_dt.tz_localize(ZoneInfo('Asia/Seoul'))
            
            # í•„í„°ë§ ì „ ë°ì´í„° ê°œìˆ˜
            original_count = len(df)
            df = df[df.index <= execution_dt]
            
            logger.info(f"ì‹œê°„ í•„í„°ë§: {execution_time} ì´ì „ ë°ì´í„°ë§Œ ì„ íƒ")
            logger.info(f"í•„í„°ë§ ê²°ê³¼: {original_count}ê°œ â†’ {len(df)}ê°œ")
        
        logger.info(f"ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ (ì„œìš¸ ì‹œê°„)")
        return df
        
    except Exception as e:
        logger.error(f"ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return pd.DataFrame()

def load_initial_history(stock_code: str, timeframe: str, base_date: str = None, period: str = None, execution_mode: str = 'LIVE') -> bool:
    """ê³¼ê±°ì˜ íŠ¹ì • ê¸°ê°„ ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ìœ¼ë¡œ ì¡°íšŒí•˜ì—¬ DBì— ì €ì¥í•©ë‹ˆë‹¤.

    `base_date`ì™€ `period`ë¥¼ ì¡°í•©í•˜ì—¬ ì¡°íšŒ ê¸°ê°„ì„ ê²°ì •í•©ë‹ˆë‹¤.
    
    Args:
        stock_code (str): ì¢…ëª© ì½”ë“œ
        timeframe (str): ì‹œê°„ ê°„ê²© (ì˜ˆ: '5m', 'd')
        base_date (str, optional): ë°ì´í„° ì¡°íšŒì˜ ê¸°ì¤€ì¼(YYYYMMDD). Noneì´ë©´ í˜„ì¬ ë‚ ì§œ.
        period (str, optional): ê¸°ì¤€ì¼ë¡œë¶€í„°ì˜ ê³¼ê±° ê¸°ê°„ (ì˜ˆ: '2y', '6m'). Noneì´ë©´ API í—ˆìš© ìµœì¥ ê¸°ê°„.
        execution_mode (str, optional): ì‹¤í–‰ ëª¨ë“œ ('LIVE' or 'SIMULATION'). Defaults to 'LIVE'.

    Returns:
        bool: 1ê°œ ì´ìƒì˜ ë°ì´í„° ì €ì¥ ì‹œ True, ê·¸ ì™¸ False.
    """
    # íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™”ëœ ê¸°ê°„ ì ìš©
    if period is None:
        period = TIMEFRAME_DEFAULT_PERIODS.get(timeframe, '2y')
        logger.info(f"íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™” ê¸°ê°„ ì ìš©: {timeframe} -> {period}")
    
    logger.info(f"ì´ˆê¸° ì´ë ¥ ë°ì´í„° ì ì¬ ì‹œì‘: {stock_code} ({TIMEFRAME_TO_LABEL.get(timeframe, timeframe)})")
    logger.info(f"ì‹¤í–‰ ëª¨ë“œ: {execution_mode}, ê¸°ì¤€ì¼: {base_date}, ê¸°ê°„: {period}")
    
    # Candle ëª¨ë¸ì—ë§Œ ë™ì ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. Stockì€ í•­ìƒ 'live'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    if execution_mode == 'SIMULATION':
        Candle.__table__.schema = 'simulation'
    else:
        # ëª…ì‹œì ìœ¼ë¡œ liveë¡œ ì„¤ì •í•˜ì—¬ ë‹¤ë¥¸ DAG ì‹¤í–‰ì— ì˜í–¥ì´ ì—†ë„ë¡ í•©ë‹ˆë‹¤.
        Candle.__table__.schema = 'live'

    logger.info(f"Target schema for Candles set to: {Candle.__table__.schema}")
    
    db: Session = SessionLocal()
    try:
        # ì¢…ëª©ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬
        stock_info = db.query(Stock).filter_by(stock_code=stock_code).first()
        if not stock_info:
            logger.error(f"[{stock_code}] DBì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¢…ëª©ì½”ë“œì…ë‹ˆë‹¤.")
            logger.error("ì¢…ëª© ì •ë³´ë¥¼ ë¨¼ì € ì ì¬í•´ì£¼ì„¸ìš”. (ì˜ˆ: python src/stock_info_collector.py)")
            return False
        
        # ê¸°ì¤€ì¼ ì„¤ì •
        if base_date is None:
            base_date = datetime.now().strftime('%Y%m%d')
        
        # ê¸°ê°„ ê³„ì‚°
        num_candles = _parse_period(period, timeframe)
        
        df_candles = pd.DataFrame()
        
        if execution_mode == 'LIVE':
            # í‚¤ì›€ API í˜¸ì¶œ
            logger.info(f"[{stock_code}] í‚¤ì›€ API í˜¸ì¶œ: {num_candles}ê°œ ìº”ë“¤ ìš”ì²­")
            
            if timeframe in ['5m', '30m', '1h']:
                # ë¶„ë´‰ ë°ì´í„°
                interval_minutes = TIMEFRAME_TO_MINUTES[timeframe]
                chart_data_obj = get_minute_chart(
                    stock_code=stock_code,
                    interval=str(interval_minutes),
                    base_date=base_date,
                    num_candles=num_candles,
                    auto_pagination=True
                )
            elif timeframe == 'd':
                # ì¼ë´‰ ë°ì´í„°
                chart_data_obj = get_daily_chart(
                    stock_code=stock_code,
                    base_date=base_date,
                    num_candles=num_candles,
                    auto_pagination=True
                )
            elif timeframe == 'w':
                # ì£¼ë´‰ ë°ì´í„°
                chart_data_obj = get_weekly_chart(
                    stock_code=stock_code,
                    base_date=base_date,
                    num_candles=num_candles,
                    auto_pagination=True
                )
            else:
                logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {timeframe}")
                return False
            
            # API í˜¸ì¶œ ì œí•œ
            time.sleep(0.2)
            
            if chart_data_obj and chart_data_obj.data:
                # ì¼ë´‰ ë°ì´í„°ë„ ì „ì²˜ë¦¬ í™œì„±í™” (ë‚ ì§œ ì¸ë±ìŠ¤ ì„¤ì •)
                chart_data_obj.preprocessing_required = True
                df_candles = chart_data_obj.to_dataframe()
                logger.info(f"[{stock_code}] API ì‘ë‹µ ë°ì´í„° ê°œìˆ˜: {len(df_candles)}")
            else:
                logger.warning(f"[{stock_code}] APIë¡œë¶€í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return False
                
        elif execution_mode == 'SIMULATION':
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
            logger.info(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ")
                        
            # ğŸ‘‡ [ìˆ˜ì •] _load_simulation_data í˜¸ì¶œ ì‹œ base_dateë¥¼ execution_timeìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
            # ì´ë ‡ê²Œ í•˜ë©´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë‹¨ê³„ì—ì„œë¶€í„° í•„í„°ë§ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
            base_datetime_str = base_date + "235959" # í•´ë‹¹ ë‚ ì§œì˜ ìì • ì§ì „ê¹Œì§€ í¬í•¨
            df_candles = _load_simulation_data(stock_code, timeframe, execution_time=base_datetime_str)
                       
            if df_candles.empty:
                logger.warning(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
            # ê¸°ê°„ í•„í„°ë§
            if period:
                start_date = _calculate_start_date(base_date, period)
                start_dt = pd.to_datetime(start_date, format='%Y%m%d')
                # íƒ€ì„ì¡´ì„ Asia/Seoulë¡œ ì„¤ì •í•˜ì—¬ ë¹„êµ (df_candles.indexëŠ” ì´ë¯¸ Asia/Seoul)
                start_dt = start_dt.tz_localize(ZoneInfo('Asia/Seoul'))
                df_candles = df_candles[df_candles.index >= start_dt]
                
            logger.info(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_candles)}ê°œ")
        
        else:
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¤í–‰ ëª¨ë“œ: {execution_mode}")
            return False
        
        # ë°ì´í„° ê²€ì¦
        if df_candles.empty:
            logger.warning(f"[{stock_code}] ì ì¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # DB ì €ì¥
        upserted_count = _db_upsert_candles(db, stock_code, timeframe, df_candles, execution_mode=execution_mode)
        
        if upserted_count > 0:
            logger.info(f"[{stock_code}] ì´ˆê¸° ì´ë ¥ ë°ì´í„° ì ì¬ ì™„ë£Œ: {upserted_count}ê°œ")
            return True
        else:
            logger.info(f"[{stock_code}] ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        logger.error(f"[{stock_code}] ì´ˆê¸° ì´ë ¥ ë°ì´í„° ì ì¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False
    finally:
        if db:
            db.close()

def collect_and_store_candles(stock_code: str, timeframe: str, execution_mode: str, execution_time: str | None = None) -> bool:
    """DBì˜ ë§ˆì§€ë§‰ ë°ì´í„° ì´í›„ ìµœì‹  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤. (ë©±ë“±ì„± ë³´ì¥)

    - DBì— í•´ë‹¹ ì¢…ëª©/íƒ€ì„í”„ë ˆì„ì˜ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    
    Args:
        stock_code (str): ì¢…ëª© ì½”ë“œ
        timeframe (str): ì‹œê°„ ê°„ê²© (ì˜ˆ: '5m', 'd')
        execution_mode (str): ì‹¤í–‰ ëª¨ë“œ ('LIVE' or 'SIMULATION')
        execution_time (str | None, optional): SIMULATION ëª¨ë“œì˜ ê¸°ì¤€ ì‹œê°„ (YYYYMMDDHHMMSS). Defaults to None.

    Returns:
        bool: 1ê°œ ì´ìƒì˜ ì‹ ê·œ ë°ì´í„° ì €ì¥ ì‹œ True, ê·¸ ì™¸ False.
    """
    logger.info(f"ì¦ë¶„ ì—…ë°ì´íŠ¸ ì‹œì‘: {stock_code} ({TIMEFRAME_TO_LABEL.get(timeframe, timeframe)})")
    logger.info(f"ì‹¤í–‰ ëª¨ë“œ: {execution_mode}, ì‹¤í–‰ ì‹œê°„: {execution_time}")
    
    # Candle ëª¨ë¸ì—ë§Œ ë™ì ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. Stockì€ í•­ìƒ 'live'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    if execution_mode == 'SIMULATION':
        Candle.__table__.schema = 'simulation'
    else:
        Candle.__table__.schema = 'live'

    logger.info(f"Target schema for Candles set to: {Candle.__table__.schema}")
    
    db: Session = SessionLocal()
    try:
        # ì¢…ëª©ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬
        stock_info = db.query(Stock).filter_by(stock_code=stock_code).first()
        if not stock_info:
            logger.error(f"[{stock_code}] DBì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¢…ëª©ì½”ë“œì…ë‹ˆë‹¤.")
            logger.error("ì¢…ëª© ì •ë³´ë¥¼ ë¨¼ì € ì ì¬í•´ì£¼ì„¸ìš”. (ì˜ˆ: python src/stock_info_collector.py)")
            return False
        
        # DBì—ì„œ í•´ë‹¹ ì¢…ëª©/íƒ€ì„í”„ë ˆì„ì˜ ê°€ì¥ ìµœì‹  ìº”ë“¤ ì¡°íšŒ
        timeframe_str = TIMEFRAME_TO_DB_FORMAT.get(timeframe, timeframe)
        latest_candle = db.query(Candle).filter(
            Candle.stock_code == stock_code,
            Candle.timeframe == timeframe_str
        ).order_by(Candle.timestamp.desc()).first()
        
        if not latest_candle:
            logger.warning(f"[{stock_code}] DBì— ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ˆê¸° ì ì¬ë¥¼ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
            return False
        
        # ìµœì‹  ìº”ë“¤ íƒ€ì„ìŠ¤íƒ¬í”„ (KST)
        latest_db_timestamp = latest_candle.timestamp.astimezone(ZoneInfo('Asia/Seoul'))
        logger.info(f"[{stock_code}] DB ìµœì‹  ìº”ë“¤: {latest_db_timestamp.strftime('%Y%m%d%H%M%S')}")
        
        df_new_candles = pd.DataFrame()
        
        if execution_mode == 'LIVE':
            # í‚¤ì›€ API í˜¸ì¶œ
            logger.info(f"[{stock_code}] í‚¤ì›€ API í˜¸ì¶œ: ìµœì‹  ë°ì´í„° ì¡°íšŒ")
            
            if timeframe in ['5m', '30m', '1h']:
                # ë¶„ë´‰ ë°ì´í„°
                interval_minutes = TIMEFRAME_TO_MINUTES[timeframe]
                chart_data_obj = get_minute_chart(
                    stock_code=stock_code,
                    interval=str(interval_minutes),
                    base_date=None,  # ìµœì‹  ë°ì´í„° ìš”ì²­
                    num_candles=500,  # ì¶©ë¶„í•œ ê°œìˆ˜ë¡œ ìš”ì²­
                    auto_pagination=False
                )
            elif timeframe == 'd':
                # ì¼ë´‰ ë°ì´í„°
                chart_data_obj = get_daily_chart(
                    stock_code=stock_code,
                    base_date=None,
                    num_candles=30,  # ìµœê·¼ 30ì¼
                    auto_pagination=False
                )
            elif timeframe == 'w':
                # ì£¼ë´‰ ë°ì´í„°
                chart_data_obj = get_weekly_chart(
                    stock_code=stock_code,
                    base_date=None,
                    num_candles=10,  # ìµœê·¼ 10ì£¼
                    auto_pagination=False
                )
            else:
                logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {timeframe}")
                return False
            
            # API í˜¸ì¶œ ì œí•œ
            time.sleep(0.2)
            
            if chart_data_obj and chart_data_obj.data:
                # ì¼ë´‰ ë°ì´í„°ë„ ì „ì²˜ë¦¬ í™œì„±í™” (ë‚ ì§œ ì¸ë±ìŠ¤ ì„¤ì •)
                chart_data_obj.preprocessing_required = True
                df_all_candles = chart_data_obj.to_dataframe()
                logger.info(f"[{stock_code}] API ì‘ë‹µ ë°ì´í„° ê°œìˆ˜: {len(df_all_candles)}")
                
                # DB ì´í›„ì˜ ì‹ ê·œ ë°ì´í„° í•„í„°ë§
                if not df_all_candles.empty:
                    mask = df_all_candles.index > latest_db_timestamp
                    df_new_candles = df_all_candles[mask].copy()
                    
                    if not df_new_candles.empty:
                        logger.info(f"[{stock_code}] ì‹ ê·œ ë°ì´í„° {len(df_new_candles)}ê°œ ë°œê²¬")
                    else:
                        logger.info(f"[{stock_code}] ì‹ ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
            else:
                logger.warning(f"[{stock_code}] APIë¡œë¶€í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return False
                
        elif execution_mode == 'SIMULATION':
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
            logger.info(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ")
            df_all_candles = _load_simulation_data(stock_code, timeframe, execution_time)
            
            if df_all_candles.empty:
                logger.warning(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DB ì´í›„ì˜ ì‹ ê·œ ë°ì´í„° í•„í„°ë§
            mask = df_all_candles.index > latest_db_timestamp
            df_new_candles = df_all_candles[mask].copy()
            
            if not df_new_candles.empty:
                logger.info(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ì‹ ê·œ ë°ì´í„° {len(df_new_candles)}ê°œ ë°œê²¬")
            else:
                logger.info(f"[{stock_code}] ì‹œë®¬ë ˆì´ì…˜ ì‹ ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        else:
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¤í–‰ ëª¨ë“œ: {execution_mode}")
            return False
        
        # ì‹ ê·œ ë°ì´í„° ì €ì¥
        if df_new_candles.empty:
            logger.info(f"[{stock_code}] ì €ì¥í•  ì‹ ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # DB ì €ì¥
        upserted_count = _db_upsert_candles(db, stock_code, timeframe, df_new_candles, execution_mode=execution_mode)
        
        if upserted_count > 0:
            logger.info(f"[{stock_code}] ì¦ë¶„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {upserted_count}ê°œ")
            return True
        else:
            logger.info(f"[{stock_code}] ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        logger.error(f"[{stock_code}] ì¦ë¶„ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False
    finally:
        if db:
            db.close()

def main():
    """CLI ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='TradeSmartAI ë°ì´í„° ìˆ˜ì§‘ ì—”ì§„')
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹')
    
    # initial ì„œë¸Œì»¤ë§¨ë“œ
    initial_parser = subparsers.add_parser('initial', help='ì´ˆê¸° ë°ì´í„° ì ì¬')
    initial_parser.add_argument('stock_code', help='ì¢…ëª© ì½”ë“œ')
    initial_parser.add_argument('timeframe', choices=['5m', '30m', '1h', 'd', 'w'], help='íƒ€ì„í”„ë ˆì„')
    initial_parser.add_argument('--base-date', help='ê¸°ì¤€ì¼ (YYYYMMDD)')
    initial_parser.add_argument('--period', help='ê¸°ê°„ (ì˜ˆ: 2y, 6m, 30d)')
    initial_parser.add_argument('--mode', choices=['LIVE', 'SIMULATION'], default='LIVE', help='ì‹¤í–‰ ëª¨ë“œ')
    
    # incremental ì„œë¸Œì»¤ë§¨ë“œ
    incremental_parser = subparsers.add_parser('incremental', help='ì¦ë¶„ ì—…ë°ì´íŠ¸')
    incremental_parser.add_argument('stock_code', help='ì¢…ëª© ì½”ë“œ')
    incremental_parser.add_argument('timeframe', choices=['5m', '30m', '1h', 'd', 'w'], help='íƒ€ì„í”„ë ˆì„')
    incremental_parser.add_argument('--mode', choices=['LIVE', 'SIMULATION'], default='LIVE', help='ì‹¤í–‰ ëª¨ë“œ')
    incremental_parser.add_argument('--execution-time', help='ì‹¤í–‰ ì‹œê°„ (SIMULATION ëª¨ë“œ, YYYYMMDDHHMMSS)')
    
    args = parser.parse_args()
    
    if args.command == 'initial':
        success = load_initial_history(
            stock_code=args.stock_code,
            timeframe=args.timeframe,
            base_date=args.base_date,
            period=args.period,
            execution_mode=args.mode
        )
        
        if success:
            logger.info("ì´ˆê¸° ë°ì´í„° ì ì¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)
        else:
            logger.error("ì´ˆê¸° ë°ì´í„° ì ì¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
    elif args.command == 'incremental':
        success = collect_and_store_candles(
            stock_code=args.stock_code,
            timeframe=args.timeframe,
            execution_mode=args.mode,
            execution_time=args.execution_time
        )
        
        if success:
            logger.info("ì¦ë¶„ ì—…ë°ì´íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)
        else:
            logger.error("ì¦ë¶„ ì—…ë°ì´íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == '__main__':
    main()