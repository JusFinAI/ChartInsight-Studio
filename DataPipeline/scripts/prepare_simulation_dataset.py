#!/usr/bin/env python3
"""Prepare simulation dataset (Parquet) - restored class-based implementation

This file is a refactored, class-based restoration of the original
`prepare_test_data.py` helper, adapted to be used as
`DataPipeline/scripts/prepare_simulation_dataset.py` for both local and
containerized execution.

Usage examples:
  python DataPipeline/scripts/prepare_simulation_dataset.py --stock_code 005930 --timeframe monthly --period 5y
"""
import argparse
import json
import os
import re
import sys
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional

try:
    import pandas as pd
    import pyarrow as pa  # noqa: F401
    import pyarrow.parquet as pq  # noqa: F401
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    print("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("   pip install pandas pyarrow")
    sys.exit(1)

# Ensure repository root and DataPipeline/src are on sys.path
repo_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
src_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'src')
if repo_root not in sys.path:
    sys.path.insert(0, repo_root)
if src_path not in sys.path:
    sys.path.insert(0, src_path)
# Also ensure DataPipeline directory is on sys.path so imports like `src.xxx` resolve
data_pipeline_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)))
if data_pipeline_dir not in sys.path:
    sys.path.insert(0, data_pipeline_dir)

from kiwoom_api.services.chart import (
    get_daily_stock_chart, get_minute_chart, get_weekly_stock_chart, get_monthly_stock_chart,
    get_daily_inds_chart, get_weekly_inds_chart, get_monthly_inds_chart,
)

from src.utils.logging_kst import configure_kst_logger

# Use module-level KST logger
logger = configure_kst_logger(__name__)


class StockDataPreparer:
    """ì£¼ì‹ ë°ì´í„° ì¤€ë¹„ í´ë˜ìŠ¤"""

    def __init__(self):
        sim_path = os.getenv("SIMULATION_DATA_PATH", "DataPipeline/data/simulation")
        self.output_dir = Path(sim_path)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„: {self.output_dir}")

    def parse_period(self, period_str: str, timeframe: str = 'daily') -> int:
        if not period_str:
            if timeframe == 'minute':
                return 390
            elif timeframe == 'daily':
                return 252
            elif timeframe == 'weekly':
                return 52
            elif timeframe == 'monthly':
                return 12
            else:
                return 100

        total_units = 0

        year_match = re.search(r'(\d+)y', period_str)
        if year_match:
            years = int(year_match.group(1))
            if timeframe == 'minute':
                total_units += years * 252 * 390
            elif timeframe == 'daily':
                total_units += years * 252
            elif timeframe == 'weekly':
                total_units += years * 52
            elif timeframe == 'monthly':
                total_units += years * 12

        month_match = re.search(r'(\d+)m', period_str)
        if month_match:
            months = int(month_match.group(1))
            if timeframe == 'minute':
                total_units += months * 21 * 390
            elif timeframe == 'daily':
                total_units += months * 21
            elif timeframe == 'weekly':
                total_units += months * 4
            elif timeframe == 'monthly':
                total_units += months

        week_match = re.search(r'(\d+)w', period_str)
        if week_match:
            weeks = int(week_match.group(1))
            if timeframe == 'minute':
                total_units += weeks * 5 * 390
            elif timeframe == 'daily':
                total_units += weeks * 5
            elif timeframe == 'weekly':
                total_units += weeks

        day_match = re.search(r'(\d+)d', period_str)
        if day_match:
            days = int(day_match.group(1))
            if timeframe == 'minute':
                total_units += days * 390
            elif timeframe == 'daily':
                total_units += days
            elif timeframe == 'weekly':
                total_units += days // 7

        hour_match = re.search(r'(\d+)h', period_str)
        if hour_match:
            hours = int(hour_match.group(1))
            if timeframe == 'minute':
                total_units += hours * 60
            elif timeframe == 'daily':
                total_units += max(1, hours // 6)
            elif timeframe == 'weekly':
                total_units += max(1, hours // (6 * 5))

        if total_units == 0 and period_str.isdigit():
            total_units = int(period_str)

        return max(1, total_units)

    def get_target_stocks(self, limit: int = 30) -> List[str]:
        stock_codes = []
        kospi_path = Path("data/kospi_code.json")
        kosdaq_path = Path("data/kosdaq_code.json")

        if not kospi_path.exists():
            logger.error(f"âŒ KOSPI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {kospi_path}")
            return []
        if not kosdaq_path.exists():
            logger.error(f"âŒ KOSDAQ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {kosdaq_path}")
            return []

        try:
            with open(kospi_path, 'r', encoding='utf-8') as f:
                kospi_data = json.load(f)
            with open(kosdaq_path, 'r', encoding='utf-8') as f:
                kosdaq_data = json.load(f)

            target_stocks = []
            for code, info in kospi_data.items():
                if info.get('upSizeName') == 'ëŒ€í˜•ì£¼':
                    target_stocks.append(code)
                    if len(target_stocks) >= limit // 2:
                        break

            for code, info in kospi_data.items():
                if info.get('upSizeName') == 'ì¤‘í˜•ì£¼' and code not in target_stocks:
                    target_stocks.append(code)
                    if len(target_stocks) >= limit * 3 // 4:
                        break

            for code, info in kosdaq_data.items():
                if info.get('upSizeName') == 'ëŒ€í˜•ì£¼' and code not in target_stocks:
                    target_stocks.append(code)
                    if len(target_stocks) >= limit:
                        break

            logger.info(f"ğŸ“Š ì„ íƒëœ íƒ€ê²Ÿ ì¢…ëª© ìˆ˜: {len(target_stocks)}")
            return target_stocks[:limit]
        except Exception as e:
            logger.error(f"âŒ íƒ€ê²Ÿ ì¢…ëª© ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def get_timeframe_label(self, timeframe: str, interval: int = 1) -> str:
        if timeframe == 'minute':
            if interval == 60:
                return '1h'
            else:
                return f'{interval}m'
        elif timeframe == 'daily':
            return 'd'
        elif timeframe == 'weekly':
            return 'w'
        elif timeframe == 'monthly':
            return 'mon'
        else:
            return timeframe

    def fetch_chart_data(self, timeframe: str, stock_code: str,
                        period: str, interval: int = 1):
        try:
            num_candles = self.parse_period(period, timeframe)
            logger.info(f"ğŸ“Š {stock_code} {timeframe} ë°ì´í„° ì¡°íšŒ ì‹œì‘ (ê¸°ê°„: {period}, ìº”ë“¤ìˆ˜: {num_candles})")
            chart_data = None

            # ì—…ì¢…/ì§€ìˆ˜ ì½”ë“œ(ì§€ìˆ˜ ì „ìš© ì—”ë“œí¬ì¸íŠ¸)ë¥¼ ì‚¬ìš©í•  ê²½ìš° ì¸ë±ìŠ¤ ì „ìš© í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
            inds_codes = {"001", "101", "013", "029", "124"}
            is_inds_code = str(stock_code) in inds_codes

            if timeframe == 'minute':
                chart_data = get_minute_chart(stock_code=stock_code, interval=str(interval), num_candles=num_candles, auto_pagination=True)
            elif timeframe == 'daily':
                if is_inds_code:
                    chart_data = get_daily_inds_chart(inds_code=stock_code, num_candles=num_candles, auto_pagination=True)
                else:
                    chart_data = get_daily_stock_chart(stock_code=stock_code, num_candles=num_candles, auto_pagination=True)
            elif timeframe == 'weekly':
                if is_inds_code:
                    chart_data = get_weekly_inds_chart(inds_code=stock_code, num_candles=num_candles, auto_pagination=True)
                else:
                    chart_data = get_weekly_stock_chart(stock_code=stock_code, num_candles=num_candles, auto_pagination=True)
            elif timeframe == 'monthly':
                if is_inds_code:
                    chart_data = get_monthly_inds_chart(inds_code=stock_code, num_candles=num_candles, auto_pagination=True)
                else:
                    chart_data = get_monthly_stock_chart(stock_code=stock_code, num_candles=num_candles, auto_pagination=True)
            else:
                logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„í”„ë ˆì„: {timeframe}")
                return None

            if chart_data:
                chart_data.preprocessing_required = True
            return chart_data
        except Exception as e:
            logger.error(f"âŒ {stock_code} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def save_to_parquet(self, chart_data, stock_code: str, timeframe: str,
                       interval: int = 1) -> bool:
        try:
            df = chart_data.to_dataframe()
            if df is None or df.empty:
                logger.warning(f"âš ï¸ {stock_code} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return False

            timeframe_label = self.get_timeframe_label(timeframe, interval)
            filename = f"{stock_code}_{timeframe_label}_full.parquet"
            filepath = self.output_dir / filename

            logger.info(f"íƒ€ì„ì¡´ ì²˜ë¦¬ ì‹œì‘: {stock_code}")

            if not isinstance(df.index, pd.DatetimeIndex):
                if 'dt' in df.columns:
                    logger.info(f"ì¼ë´‰/ì£¼ë´‰ ë°ì´í„° ì²˜ë¦¬: 'dt' ì»¬ëŸ¼ì„ DatetimeIndexë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                    df.index = pd.to_datetime(df['dt'], format='%Y%m%d')
                else:
                    logger.error(f"âŒ {stock_code} ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ DatetimeIndexë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return False
            else:
                logger.info(f"ì´ë¯¸ DatetimeIndexë¡œ ì²˜ë¦¬ë¨ (ChartDataì—ì„œ ì²˜ë¦¬)")

            if isinstance(df.index, pd.DatetimeIndex):
                if df.index.tz is None:
                    df.index = df.index.tz_localize('Asia/Seoul')
                    logger.info(f"íƒ€ì„ì¡´ ì •ë³´ ë¶€ì—¬: Naive -> Asia/Seoul")
                else:
                    df.index = df.index.tz_convert('Asia/Seoul')
            else:
                logger.error(f"âŒ {stock_code} ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ DatetimeIndexë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

            df.index = df.index.tz_convert('UTC')
            logger.info(f"íƒ€ì„ì¡´ í‘œì¤€í™” ì™„ë£Œ: Asia/Seoul -> UTC (timezone-aware)")

            df.to_parquet(filepath, index=True)

            first_date = df.index.min().strftime('%Y-%m-%d')
            last_date = df.index.max().strftime('%Y-%m-%d')

            logger.info(f"âœ… {stock_code} ì €ì¥ ì™„ë£Œ: {filepath}")
            logger.info(f"   ğŸ“Š ë°ì´í„° ë²”ìœ„: {first_date} ~ {last_date} ({len(df)}ê°œ ìº”ë“¤)")
            return True
        except Exception as e:
            logger.error(f"âŒ {stock_code} ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def process_single_stock(self, timeframe: str, stock_code: str,
                           period: str, interval: int = 1) -> bool:
        logger.info(f"ğŸš€ {stock_code} ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")

        chart_data = self.fetch_chart_data(timeframe, stock_code, period, interval)
        if chart_data is None:
            return False

        success = self.save_to_parquet(chart_data, stock_code, timeframe, interval)
        time.sleep(0.5)
        return success

    def process_all_targets(self, timeframe: str,
                          period: str, interval: int = 1) -> Dict[str, bool]:
        logger.info(f"ğŸ¯ íƒ€ê²Ÿ ì¢…ëª© ì „ì²´ ì²˜ë¦¬ ì‹œì‘ (timeframe: {timeframe}, period: {period})")

        target_stocks = self.get_target_stocks()
        if not target_stocks:
            logger.error("âŒ íƒ€ê²Ÿ ì¢…ëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        results = {}
        for i, stock_code in enumerate(target_stocks, 1):
            logger.info(f"ğŸ“ˆ ì§„í–‰ìƒí™©: {i}/{len(target_stocks)} - {stock_code}")
            try:
                result = self.process_single_stock(timeframe, stock_code, period, interval)
                results[stock_code] = result
                if result:
                    logger.info(f"âœ… {stock_code} ì„±ê³µ")
                else:
                    logger.warning(f"âš ï¸ {stock_code} ì‹¤íŒ¨")
            except Exception as e:
                logger.error(f"âŒ {stock_code} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                results[stock_code] = False

            if i < len(target_stocks):
                time.sleep(0.5)

        success_count = sum(1 for success in results.values() if success)
        logger.info(f"ğŸ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{len(target_stocks)} ì„±ê³µ")
        return results


def create_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description='ì£¼ì‹ ë°ì´í„° í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ë„êµ¬ (ì‹œë®¬ë ˆì´ì…˜ìš©)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        '--timeframe',
        required=True,
        choices=['minute', 'daily', 'weekly', 'monthly'],
        help='ë°ì´í„° íƒ€ì„í”„ë ˆì„'
    )

    parser.add_argument(
        '--period',
        required=True,
        help='ì¡°íšŒ ê¸°ê°„ (ì˜ˆ: 1d, 5d, 1w, 1m, 1y, 2y) - í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ ê³¼ê±°'
    )

    parser.add_argument('--stock_code', help='ì¢…ëª© ì½”ë“œ (ì˜ˆ: 005930)')

    parser.add_argument(
        '--interval',
        type=int,
        default=5,
        choices=[1, 3, 5, 10, 15, 30, 60],
        help='ë¶„ë´‰ ê°„ê²© (ê¸°ë³¸ê°’: 5ë¶„)'
    )

    parser.add_argument('--all-targets', action='store_true', help='30ê°œ íƒ€ê²Ÿ ì¢…ëª© ì „ì²´ ì²˜ë¦¬')
    return parser


def validate_args(args) -> bool:
    if not args.stock_code and not getattr(args, 'all_targets', False):
        logger.error("âŒ --stock_code ë˜ëŠ” --all-targets ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        return False

    period_pattern = r'^(\d+[ymdwh])+$|^\d+$'
    if not re.match(period_pattern, args.period):
        logger.error(f"âŒ ì˜ëª»ëœ ê¸°ê°„ í˜•ì‹: {args.period} (ì˜ˆ: 1d, 5d, 1w, 1m, 1y, 2y)")
        return False

    if args.timeframe != 'minute' and args.interval != 5:
        logger.warning(f"âš ï¸ {args.timeframe}ì—ì„œëŠ” interval íŒŒë¼ë¯¸í„°ê°€ ë¬´ì‹œë©ë‹ˆë‹¤.")

    return True


def main():
    try:
        parser = create_parser()
        args = parser.parse_args()

        if not validate_args(args):
            parser.print_help()
            sys.exit(1)

        preparer = StockDataPreparer()

        logger.info("=" * 60)
        logger.info("ğŸš€ ì‹œë®¬ë ˆì´ì…˜ìš© ì£¼ì‹ ë°ì´í„° ìƒì„± ì‹œì‘")
        logger.info(f"ğŸ“‹ íƒ€ì„í”„ë ˆì„: {args.timeframe}")
        logger.info(f"â° ì¡°íšŒ ê¸°ê°„: {args.period} (í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ ê³¼ê±°)")
        if args.timeframe == 'minute':
            logger.info(f"ğŸ• ë¶„ë´‰ ê°„ê²©: {args.interval}ë¶„")
        logger.info(f"ğŸ“ íŒŒì¼ëª… í˜•ì‹: {{stock_code}}_{{timeframe}}_full.parquet")
        logger.info("ğŸ• íƒ€ì„ì¡´ ì²˜ë¦¬: UTC ê¸°ì¤€ naive í˜•ì‹ìœ¼ë¡œ í‘œì¤€í™”")
        logger.info("=" * 60)

        if getattr(args, 'all_targets', False):
            results = preparer.process_all_targets(
                timeframe=args.timeframe,
                period=args.period,
                interval=args.interval,
            )
            success_count = sum(1 for success in results.values() if success)
            logger.info(f"ğŸ ì „ì²´ ì²˜ë¦¬ ê²°ê³¼: {success_count}/{len(results)} ì„±ê³µ")
            if success_count == 0:
                sys.exit(1)
        else:
            success = preparer.process_single_stock(
                timeframe=args.timeframe,
                stock_code=args.stock_code,
                period=args.period,
                interval=args.interval,
            )
            if not success:
                logger.error(f"âŒ {args.stock_code} ì²˜ë¦¬ ì‹¤íŒ¨")
                sys.exit(1)
            else:
                logger.info(f"âœ… {args.stock_code} ì²˜ë¦¬ ì™„ë£Œ")

        logger.info("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


