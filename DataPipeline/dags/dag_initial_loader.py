# DAG íŒŒì¼: ìš´ì˜ìš© ì´ˆê¸° ë°ì´í„° ì ì¬ (ìˆ˜ë™ ì‹¤í–‰ ì „ìš©)
"""
TradeSmartAI ì´ˆê¸° ë°ì´í„° ì ì¬ DAG

ì´ DAGëŠ” ìš´ì˜ìê°€ í•„ìš”í•  ë•Œ ìˆ˜ë™ìœ¼ë¡œ ê³¼ê±° ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ ì ì¬í•˜ê¸° ìœ„í•œ ìš©ë„ì…ë‹ˆë‹¤.
Airflow UIì˜ "Trigger DAG with config" ê¸°ëŠ¥ì„ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ ì‹¤í–‰ë©ë‹ˆë‹¤.

Task êµ¬ì¡°:
1. stock_info_load_task: ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ (ì „ì œì¡°ê±´)
2. initial_load_task: ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ (ë©”ì¸ ì‘ì—…)

ì§€ì› ëª¨ë“œ:
1. ë‹¨ì¼ ì‘ì—… ëª¨ë“œ: íŠ¹ì • ì¢…ëª©ì˜ íŠ¹ì • íƒ€ì„í”„ë ˆì„ë§Œ ì ì¬
2. íŠ¹ì • ì¢…ëª© ì „ì²´ ëª¨ë“œ: íŠ¹ì • ì¢…ëª©ì˜ ëª¨ë“  íƒ€ì„í”„ë ˆì„ ì ì¬
3. ì¼ê´„ ì‘ì—… ëª¨ë“œ: ëª¨ë“  íƒ€ê²Ÿ ì¢…ëª©ì˜ ëª¨ë“  íƒ€ì„í”„ë ˆì„ ì ì¬ (ì´ 150ê°œ ì‘ì—…)

ì‚¬ìš© ì˜ˆì‹œ:
- ë‹¨ì¼ ì‘ì—…: {"stock_code": "005930", "timeframe": "d", "period": "2y"}
- íŠ¹ì • ì¢…ëª© ì „ì²´: {"stock_code": "005930", "period": "2y"}
- ì¼ê´„ ì‘ì—…: {"run_all_targets": true, "period": "2y"}
"""

import time
import pendulum
from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator
from airflow.exceptions import AirflowException
from airflow.models.param import Param

# --- ê³µí†µ ëª¨ë“ˆ ë° ë³€ìˆ˜ ë¡œë“œ ---
from src.data_collector import load_initial_history
from src.database import SessionLocal, Stock
from src.master_data_manager import sync_stock_master_to_db
from src.utils.common_helpers import get_target_stocks, get_all_filtered_stocks

DEFAULT_ARGS = {
    'owner': 'tradesmart_ai',
    'retries': 1,  # ì´ˆê¸° ì ì¬ëŠ” ì¬ì‹œë„ ìµœì†Œí™”
    'retry_delay': pendulum.duration(minutes=5),  # ì¬ì‹œë„ ê°„ 5ë¶„ ëŒ€ê¸°
}

# ì§€ì›í•˜ëŠ” íƒ€ì„í”„ë ˆì„ ëª©ë¡
TARGET_TIMEFRAMES = ['5m', '30m', '1h', 'd', 'w', 'mon']

# íƒ€ì„í”„ë ˆì„ë³„ ì¡°íšŒ ê¸°ê°„ ì„¤ì •
TIMEFRAME_PERIOD_MAP = {
    '5m': '3M',   # 5ë¶„ë´‰ì€ ìµœê·¼ 3ê°œì›”
    '30m': '6M',  # 30ë¶„ë´‰ì€ ìµœê·¼ 6ê°œì›”
    '1h': '1y',   # 1ì‹œê°„ë´‰ì€ ìµœê·¼ 1ë…„
    'd': '5y',    # ì¼ë´‰ì€ 5ë…„
    'w': '10y',   # ì£¼ë´‰ì€ 10ë…„
    'mon': '10y', # ì›”ë´‰ì€ 10ë…„ (RS ê³„ì‚°ì— í•„ìˆ˜)
}
# ---------------------------------------------

# dags/dag_initial_loader.py

def _run_stock_info_load_task(**kwargs):
    """
    (í†µí•© ë¡œì§) ì™¸ë¶€ APIì™€ DBì˜ ì „ì²´ ì¢…ëª© ë§ˆìŠ¤í„°ë¥¼ ë™ê¸°í™”í•©ë‹ˆë‹¤.
    dag_daily_batchì™€ ë™ì¼í•œ í‘œì¤€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ì •ì±…ì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    import logging
    from src.database import SessionLocal
    # sync_stock_master_to_dbë¥¼ ì§ì ‘ ì„í¬íŠ¸í•˜ì—¬ ì‚¬ìš©
    from src.master_data_manager import sync_stock_master_to_db

    logger = logging.getLogger(__name__)
    logger.info("í‘œì¤€ ë™ê¸°í™” í•¨ìˆ˜(sync_stock_master_to_db)ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¢…ëª© ë§ˆìŠ¤í„°ë¥¼ ë™ê¸°í™”í•©ë‹ˆë‹¤.")

    db_session = SessionLocal()
    try:
        # ì´ TaskëŠ” DB ìƒíƒœë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ëª©ì ì´ë¯€ë¡œ, ë°˜í™˜ê°’ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        sync_stock_master_to_db(db_session)
        logger.info("ì¢…ëª© ë§ˆìŠ¤í„° ë™ê¸°í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì¢…ëª© ë§ˆìŠ¤í„° ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise
    finally:
        db_session.close()
        
def _run_initial_load_task(db_session=None, **kwargs):
    """
    Airflow UIì˜ "Trigger DAG with config"ë¥¼ í†µí•´ ì „ë‹¬ëœ íŒŒë¼ë¯¸í„°ë¥¼ ì½ì–´,
    ëŒ€ìƒì„ ì„ ì •í•œ í›„ load_initial_history í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ì–´ëŒ‘í„° í•¨ìˆ˜.
    """
    dag_run = kwargs.get('dag_run')
    config = dag_run.conf if dag_run and dag_run.conf else {}
    print(f"ğŸ“‹ ì…ë ¥ë°›ì€ ì„¤ì •: {config}")

    # --- DB Session Management ---
    session_owner = False
    if db_session is None:
        db_session = SessionLocal()
        session_owner = True
    # -----------------------------

    try:
        # 1. ëŒ€ìƒ ì¢…ëª© ì„ ì • ë¡œì§
        target_stocks = []
        mode_description = ""
        if config.get('stock_codes'):
            mode_description = "ğŸ¯ 'íŠ¹ì • ì¢…ëª©' ëª¨ë“œ"
            target_stocks = [code.strip() for code in config['stock_codes'].split(',') if code.strip()]
            print(f"ìˆ˜ë™ ëª¨ë“œë¡œ íŠ¹ì • ì¢…ëª©ì— ëŒ€í•´ ì‹¤í–‰í•©ë‹ˆë‹¤: {target_stocks}")
        else:
            rows = db_session.query(Stock.stock_code).filter(Stock.is_active == True, Stock.backfill_needed == True).all()
            target_stocks = [r.stock_code for r in rows]
            mode_description = "ğŸ”¥ 'ìë™ ëª¨ë“œ(ë°±í•„ ëŒ€ìƒ ì¡°íšŒ)'"
            print(f"ìë™ ëª¨ë“œë¡œ DBì—ì„œ ë°±í•„ ëŒ€ìƒ {len(target_stocks)}ê±´ì„ ì¡°íšŒí•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.")

        if not target_stocks:
            print("ì²˜ë¦¬í•  ëŒ€ìƒ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        # 2. ê³µí†µ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        base_date = config.get('base_date')
        execution_mode = config.get('execution_mode', 'LIVE')
        timeframes_to_process = config.get('timeframes', ['5m', '30m', '1h', 'd', 'w', 'mon'])

        # 3. ì‘ì—… ì‹¤í–‰ ë¡œì§
        print(f'\n{'='*60}')
        print(f'ğŸš€ {mode_description}ìœ¼ë¡œ ì´ˆê¸° ì ì¬ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.')
        print(f'ğŸ“Š ëŒ€ìƒ ì¢…ëª© ìˆ˜: {len(target_stocks)}ê°œ')
        print(f'â° íƒ€ì„í”„ë ˆì„: {timeframes_to_process}')
        print(f'ğŸ“… ê¸°ì¤€ì¼: {base_date or 'í˜„ì¬ ë‚ ì§œ'}')
        print(f'ğŸ“† ê¸°ê°„: íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™”ëœ ê¸°ê°„ ì‚¬ìš©')
        print(f'ğŸ”§ ì‹¤í–‰ ëª¨ë“œ: {execution_mode}')
        print(f'{'='*60}\n')

        success_count = 0
        fail_count = 0
        total_tasks = len(target_stocks) * len(timeframes_to_process)
        current_task = 0

        # --- ì‹œì¥ ì§€ìˆ˜(ì¸ë±ìŠ¤) ê³ ì • ì ì¬ (í•­ìƒ ìˆ˜í–‰, stock_limit ì˜í–¥ ì—†ìŒ) ---
        from sqlalchemy.dialects.postgresql import insert
        index_info = [
            {'stock_code': '001', 'stock_name': 'KOSPI', 'market_name': 'INDEX', 'is_active': True, 'backfill_needed': False},
            {'stock_code': '101', 'stock_name': 'KOSDAQ', 'market_name': 'INDEX', 'is_active': True, 'backfill_needed': False}
        ]
        print("ğŸ”” ì‹œì¥ ì§€ìˆ˜ ì •ë³´ë¥¼ 'stocks' í…Œì´ë¸”ì— UPSERT í•©ë‹ˆë‹¤.")
        stmt = insert(Stock).values(index_info)
        update_cols = {c.name: getattr(stmt.excluded, c.name) for c in Stock.__table__.columns if c.name != 'stock_code'}
        final_stmt = stmt.on_conflict_do_update(index_elements=['stock_code'], set_=update_cols)
        db_session.execute(final_stmt)
        db_session.commit()

        index_codes = ['001', '101']  # KOSPI, KOSDAQ
        index_timeframes = ['mon']
        print(f"ğŸ”” ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ê³ ì • ì ì¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤: {index_codes} x {index_timeframes}")
        for idx_code in index_codes:
            for timeframe in index_timeframes:
                current_task += 1
                total_tasks += 1
                period_for_timeframe = TIMEFRAME_PERIOD_MAP.get(timeframe, '1y')
                print(f"\n[INDEX {current_task}] ì²˜ë¦¬ ì¤‘: {idx_code} - {timeframe} (ê¸°ê°„: {period_for_timeframe})")
                try:
                    success = load_initial_history(
                        stock_code=idx_code, timeframe=timeframe, base_date=base_date, period=period_for_timeframe, execution_mode=execution_mode
                    )
                    if success:
                        success_count += 1
                        print(f"âœ… ì„±ê³µ: {idx_code} - {timeframe}")
                    else:
                        fail_count += 1
                        print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {idx_code} - {timeframe}")
                except Exception as e:
                    fail_count += 1
                    print(f"âŒ ì‹¤íŒ¨: {idx_code} - {timeframe}: {str(e)}")
                time.sleep(0.3)
        print(f"ğŸ”” ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ê³ ì • ì ì¬ ì™„ë£Œ. ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {fail_count}")

        for stock_code in target_stocks:
            all_success = True
            for timeframe in timeframes_to_process:
                current_task += 1
                # íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™”ëœ ê¸°ê°„ ì¡°íšŒ
                period_for_timeframe = TIMEFRAME_PERIOD_MAP.get(timeframe, '1y')
                print(f"\n[{current_task}/{total_tasks}] ì²˜ë¦¬ ì¤‘: {stock_code} - {timeframe} (ê¸°ê°„: {period_for_timeframe})")
                try:
                    success = load_initial_history(
                        stock_code=stock_code, timeframe=timeframe, base_date=base_date, period=period_for_timeframe, execution_mode=execution_mode
                    )
                    if success:
                        success_count += 1
                        print(f"âœ… ì„±ê³µ: {stock_code} - {timeframe}")
                    else:
                        fail_count += 1
                        all_success = False
                        print(f"âš ï¸ ë°ì´í„° ì—†ìŒ:{stock_code} - {timeframe}")
                except Exception as e:
                    fail_count += 1
                    all_success = False
                    print(f"âŒ ì‹¤íŒ¨: {stock_code} - {timeframe}: {str(e)}")
                time.sleep(0.3) # API ì„œë²„ ë³´í˜¸
            
            if all_success:
                db_session.query(Stock).filter(Stock.stock_code == stock_code).update({"backfill_needed": False})
                db_session.commit()
                print(f"'{stock_code}' ë°±í•„ ì™„ë£Œ. backfill_needed=Falseë¡œ ì—…ë°ì´íŠ¸.")

        # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ì´í•˜ ìƒëµ)

    finally:
        if session_owner:
            db_session.close()

    # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ì´ˆê¸° ì ì¬ ì™„ë£Œ")
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨/ë°ì´í„° ì—†ìŒ: {fail_count}ê°œ")
    print(f"ğŸ“Š ì „ì²´: {total_tasks}ê°œ")
    print(f"{'='*60}\n")

    if fail_count > total_tasks * 0.3:
        raise AirflowException(f"ë„ˆë¬´ ë§ì€ ì‘ì—…({fail_count}/{total_tasks})ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    if execution_mode == 'SIMULATION' and base_date:
        
        from airflow.models import Variable
        from datetime import datetime, timedelta
        from pathlib import Path
        import pandas as pd

        print("\nğŸš€ ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ ìë™ ì„¤ì • ì‹œì‘...")

        # 1. simulation_base_time ì„¤ì • (ê¸°ì¤€ì¼ ë‹¤ìŒ ê±°ë˜ì¼ ì˜¤ì „ 9ì‹œ)
        base_date_obj = datetime.strptime(base_date, '%Y%m%d')
        next_day_obj = base_date_obj + timedelta(days=1)
        
        # ë‹¤ìŒë‚ ì´ ì£¼ë§(í† :5, ì¼:6)ì´ë©´ ì›”ìš”ì¼(0)ìœ¼ë¡œ ì´ë™
        if next_day_obj.weekday() >= 5:
            next_day_obj += timedelta(days=7 - next_day_obj.weekday())
        
        start_time_str = next_day_obj.strftime('%Y%m%d') + '090000'
        Variable.set('simulation_base_time', start_time_str)
        print(f"  âœ… simulation_base_time ì„¤ì • ì™„ë£Œ: {start_time_str}")

        # 2. simulation_end_time ì„¤ì • (Parquet íŒŒì¼ì˜ ë§ˆì§€ë§‰ ì‹œê°„ ê¸°ì¤€)
        stock_for_endtime = config.get('stock_code')
        if not stock_for_endtime:
             # ì¼ê´„ ëª¨ë“œì¼ ê²½ìš°, ê¸°ì¤€ì´ ë  ì¢…ëª©ì„ íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ì¢…ëª©ìœ¼ë¡œ ì‚¬ìš©
            stock_for_endtime = get_target_stocks()[0]

        import os
        from pathlib import Path

        sim_base = os.getenv('SIMULATION_DATA_PATH')
        if not sim_base:
            raise AirflowException("í™˜ê²½ë³€ìˆ˜ SIMULATION_DATA_PATHê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: export SIMULATION_DATA_PATH=/opt/airflow/data/simulation")

        parquet_path = Path(sim_base) / f"{stock_for_endtime}_5m_full.parquet"
        
        end_time_str = None
        if parquet_path.exists():
            df = pd.read_parquet(parquet_path)
            if not df.empty:
                last_timestamp = df.index.max()
                end_time_str = last_timestamp.strftime('%Y%m%d%H%M%S')
                Variable.set('simulation_end_time', end_time_str)
                print(f"  âœ… simulation_end_time ì„¤ì • ì™„ë£Œ (ë°ì´í„° ê¸°ì¤€): {end_time_str}")
        
        if not end_time_str:
            # Parquet íŒŒì¼ì„ ì°¾ì§€ ëª»í•˜ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°, ì•ˆì „í•˜ê²Œ 2ì¼ ë’¤ë¡œ ì„¤ì •
            fallback_end_time_obj = next_day_obj + timedelta(days=2)
            fallback_end_time_str = fallback_end_time_obj.strftime('%Y%m%d') + '153000'
            Variable.set('simulation_end_time', fallback_end_time_str)
            print(f"  âš ï¸ Parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì¢…ë£Œ ì‹œê°„ìœ¼ë¡œ ì„¤ì •: {fallback_end_time_str}")

        # 3. system_modeë¥¼ SIMULATIONìœ¼ë¡œ ìë™ ì„¤ì •
        Variable.set('system_mode', 'SIMULATION')
        print(f"  âœ… system_mode ì„¤ì • ì™„ë£Œ: SIMULATION")
        print("="*60)

# DAG ì •ì˜
with DAG(
    dag_id='dag_initial_loader',
    default_args=DEFAULT_ARGS,
    schedule_interval=None,  # ìˆ˜ë™ ì‹¤í–‰ ì „ìš© (ë§¤ìš° ì¤‘ìš”!)
    start_date=pendulum.datetime(2025, 7, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=['Utility', 'Backfill', 'Manual'],
    description='[ìœ í‹¸ë¦¬í‹°] ê³¼ê±° ë°ì´í„° ëŒ€ëŸ‰ ì ì¬ (ì´ˆê¸° êµ¬ì¶• ë° ë°ì´í„° ë°±í•„ìš©)',
    params={
        "stock_codes": Param(
            type=["null", "string"],
            default=None,
            title="ğŸ¯ íŠ¹ì • ì¢…ëª© ëŒ€ìƒ ì‹¤í–‰",
            description="ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì—¬ëŸ¬ ì¢…ëª©ì€ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. (ì˜ˆ: 005930,000660)"
        ),
        "stock_limit": Param(
            type="integer",
            default=0,
            title="ì¢…ëª© ìˆ˜ ì œí•œ (0=ì œí•œ ì—†ìŒ)",
            description="í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ ì²˜ë¦¬í•  ì¢…ëª© ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤. 0 ë˜ëŠ” ìŒìˆ˜ì´ë©´ í•„í„°ë§ëœ ì „ì²´ ì¢…ëª©ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."
        ),
        "timeframes": Param(
            type=["null", "array"],
            default=['5m', '30m', '1h', 'd', 'w', 'mon'],
            title="íƒ€ì„í”„ë ˆì„ ëª©ë¡",
            description="ìˆ˜ì§‘í•  íƒ€ì„í”„ë ˆì„ ëª©ë¡ì„ ì§€ì •í•©ë‹ˆë‹¤. ë¹„ì›Œë‘ë©´ ê¸°ë³¸ 6ê°œ íƒ€ì„í”„ë ˆì„(5m, 30m, 1h, d, w, mon)ì„ ëª¨ë‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        ),
        "base_date": Param(
            type=["null", "string"],
            default=None,
            title="ê¸°ì¤€ì¼ (YYYYMMDD)",
            description="ë°ì´í„° ì¡°íšŒì˜ ê¸°ì¤€ì¼. ë¹„ì›Œë‘ë©´ í˜„ì¬ ë‚ ì§œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
        ),
        "execution_mode": Param(
            type="string",
            default="LIVE",
            title="ì‹¤í–‰ ëª¨ë“œ",
            description="LIVE: ì‹¤ì œ API í˜¸ì¶œ, SIMULATION: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©",
            enum=["LIVE", "SIMULATION"]
        )
    },
    doc_md="""
    ### [ìœ í‹¸ë¦¬í‹°] ê³¼ê±° ë°ì´í„° ëŒ€ëŸ‰ ì ì¬ DAG

    ì´ DAGëŠ” ì‹œìŠ¤í…œì„ ìµœì´ˆë¡œ êµ¬ì¶•í•˜ê±°ë‚˜, íŠ¹ì • ì¢…ëª©ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë³´ê°•(ë°±í•„)í•´ì•¼ í•  ë•Œ **ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰**í•˜ëŠ” ê´€ë¦¬ìš© ë„êµ¬ì…ë‹ˆë‹¤.

    #### ì‹¤í–‰ ëª¨ë“œ
    - **ìë™ ëª¨ë“œ (ê¸°ë³¸)**: `stock_codes` íŒŒë¼ë¯¸í„°ë¥¼ ë¹„ì›Œë‘ê³  ì‹¤í–‰í•˜ë©´, DBì—ì„œ `backfill_needed=True`ë¡œ í‘œì‹œëœ ëª¨ë“  ì¢…ëª©ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ê³¼ê±° ë°ì´í„°ë¥¼ ì ì¬í•©ë‹ˆë‹¤.
    - **ìˆ˜ë™ ëª¨ë“œ**: `stock_codes`ì— ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ì—¬ íŠ¹ì • ì¢…ëª©ì˜ ê³¼ê±° ë°ì´í„°ë§Œ ì„ ë³„ì ìœ¼ë¡œ ì ì¬í•©ë‹ˆë‹¤. ì‹ ê·œ ê´€ì‹¬ ì¢…ëª© ì¶”ê°€ë‚˜ ë°ì´í„° ìœ ì‹¤ ì‹œ ë³µêµ¬ ìš©ë„ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    **ì£¼ì˜**: ì´ DAGëŠ” ëŒ€ëŸ‰ì˜ API í˜¸ì¶œì„ ìœ ë°œí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    """
) as dag:
    
    # ë‹¨ì¼ Task: ì¢…ëª© ì •ë³´ ì ì¬
    stock_info_load_task = PythonOperator(
        task_id='stock_info_load_task',
        python_callable=_run_stock_info_load_task,
        provide_context=True,
        # Pool ì œê±°: ì¢…ëª© ì •ë³´ ì ì¬ëŠ” API í˜¸ì¶œì´ ì•„ë‹ˆë¯€ë¡œ Pool ë¶ˆí•„ìš”
        doc_md="""
        ### ì¢…ëª© ì •ë³´ ì ì¬ Task
        
        ì´ TaskëŠ” ì¢…ëª© ì •ë³´ë¥¼ DBì— ì ì¬í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.
        ì´ëŠ” ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ì˜ ì „ì œì¡°ê±´ì´ë©°, ëŒ€ëŸ‰ ë°ì´í„° ì ì¬ ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        
        **ì£¼ì˜**: ì´ TaskëŠ” ëŒ€ëŸ‰ ë°ì´í„° ì ì¬ ì‘ì—…ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ ì™„ë£Œë©ë‹ˆë‹¤.
        """
    )
    
    # ë‹¨ì¼ Task: ì´ˆê¸° ë°ì´í„° ì ì¬
    initial_load_task = PythonOperator(
        task_id='initial_load_task',
        python_callable=_run_initial_load_task,
        provide_context=True,
        # Pool ì œê±°: ìˆœì°¨ ì‹¤í–‰(for ë¬¸)ì´ë¯€ë¡œ Pool ë¶ˆí•„ìš”, ì¦ë¶„ ì—…ë°ì´íŠ¸ DAGì—ì„œ Pool ì‚¬ìš© ì˜ˆì •
        doc_md="""
        ### ì´ˆê¸° ë°ì´í„° ì ì¬ Task
        
        ì´ TaskëŠ” ì „ë‹¬ëœ íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ì„¸ ê°€ì§€ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤:
        
        **1. ì¼ê´„ ì‘ì—… ëª¨ë“œ (run_all_targets=true)**
        - 30ê°œ íƒ€ê²Ÿ ì¢…ëª© Ã— 5ê°œ íƒ€ì„í”„ë ˆì„ = ì´ 150ê°œ ì‘ì—… ìˆ˜í–‰
        - ê° ì‘ì—… ì‚¬ì´ì— 0.3ì´ˆ ëŒ€ê¸° (ìˆœì°¨ ì‹¤í–‰ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ Rate Limiting)
        - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 1ì‹œê°„
        
        **2. íŠ¹ì • ì¢…ëª© ì „ì²´ ëª¨ë“œ (stock_codeë§Œ ì§€ì •)**
        - 1ê°œ ì¢…ëª© Ã— 5ê°œ íƒ€ì„í”„ë ˆì„ = ì´ 5ê°œ ì‘ì—… ìˆ˜í–‰
        - ê° ì‘ì—… ì‚¬ì´ì— 0.3ì´ˆ ëŒ€ê¸°
        
        **3. ë‹¨ì¼ ì‘ì—… ëª¨ë“œ (stock_code + timeframe ì§€ì •)**
        - 1ê°œ ì¢…ëª© Ã— 1ê°œ íƒ€ì„í”„ë ˆì„ = 1ê°œ ì‘ì—… ìˆ˜í–‰
        
        **ê³µí†µ ê¸°ëŠ¥:**
        - íŒŒë¼ë¯¸í„° ê²€ì¦
        - load_initial_history í•¨ìˆ˜ í˜¸ì¶œ
        - ì§„í–‰ ìƒí™© ë° ê²°ê³¼ ë¡œê¹…
        - ì‹¤íŒ¨ìœ¨ì´ 30% ì´ˆê³¼ ì‹œ DAG ì‹¤íŒ¨ ì²˜ë¦¬
        
        **Pool ì‚¬ìš© ì•ˆ í•¨**: ìˆœì°¨ ì‹¤í–‰ì´ë¯€ë¡œ Pool ë¶ˆí•„ìš” (ì¦ë¶„ ì—…ë°ì´íŠ¸ DAGì—ì„œ Pool ì‚¬ìš© ì˜ˆì •)
        """
    )
    
    # ì˜ì¡´ì„± ì„¤ì •
    stock_info_load_task >> initial_load_task 