# DAG íŒŒì¼: ìš´ì˜ìš© ì´ˆê¸° ë°ì´í„° ì ì¬ (ìˆ˜ë™ ì‹¤í–‰ ì „ìš©)
"""
TradeSmartAI ì´ˆê¸° ë°ì´í„° ì ì¬ DAG

ì´ DAGëŠ” ìš´ì˜ìê°€ í•„ìš”í•  ë•Œ ìˆ˜ë™ìœ¼ë¡œ ê³¼ê±° ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ ì ì¬í•˜ê¸° ìœ„í•œ ìš©ë„ì…ë‹ˆë‹¤.
Airflow UIì˜ "Trigger DAG with config" ê¸°ëŠ¥ì„ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ ì‹¤í–‰ë©ë‹ˆë‹¤.

Task êµ¬ì¡°:
1. stock_info_load_task: ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ (ì „ì œì¡°ê±´)
2. initial_load_task: ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ (ë©”ì¸ ì‘ì—…)

ì§€ì› ëª¨ë“œ:
1. ë‹¨ì¼ ì‘ì—… ëª¨ë“œ: íŠ¹ì • ì¢…ëª©ì˜ íŠ¹ì • íƒ€ì„í”„ë ˆì„ë§Œ ì ì¬
2. íŠ¹ì • ì¢…ëª© ì „ì²´ ëª¨ë“œ: íŠ¹ì • ì¢…ëª©ì˜ ëª¨ë“  íƒ€ì„í”„ë ˆì„ ì ì¬
3. ì¼ê´„ ì‘ì—… ëª¨ë“œ: ëª¨ë“  íƒ€ê²Ÿ ì¢…ëª©ì˜ ëª¨ë“  íƒ€ì„í”„ë ˆì„ ì ì¬ (ì´ 150ê°œ ì‘ì—…)

ì‚¬ìš© ì˜ˆì‹œ:
- ë‹¨ì¼ ì‘ì—…: {"stock_code": "005930", "timeframe": "d", "period": "2y"}
- íŠ¹ì • ì¢…ëª© ì „ì²´: {"stock_code": "005930", "period": "2y"}
- ì¼ê´„ ì‘ì—…: {"run_all_targets": true, "period": "2y"}
"""

import time
import pendulum
import json
import logging
from datetime import datetime, time as dt_time, timedelta
from zoneinfo import ZoneInfo

from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator
from airflow.exceptions import AirflowException
from airflow.models.param import Param
from airflow.models import Variable

# --- ê³µí†µ ëª¨ë“ˆ ë° ë³€ìˆ˜ ë¡œë“œ ---
from src.data_collector import load_initial_history, create_simulation_snapshot
from src.database import SessionLocal, Stock, Sector
from src.kiwoom_api.services.master import get_sector_list
from sqlalchemy.dialects.postgresql import insert

            

# ì§€ì›í•˜ëŠ” íƒ€ì„í”„ë ˆì„ ëª©ë¡
TARGET_TIMEFRAMES = ['5m', '30m', '1h', 'd', 'w', 'mon']

# íƒ€ì„í”„ë ˆì„ë³„ ì¡°íšŒ ê¸°ê°„ ì„¤ì •
TIMEFRAME_PERIOD_MAP = {
    '5m': '3M',   # 5ë¶„ë´‰ì€ ìµœê·¼ 3ê°œì›”
    '30m': '6M',  # 30ë¶„ë´‰ì€ ìµœê·¼ 6ê°œì›”
    '1h': '1y',   # 1ì‹œê°„ë´‰ì€ ìµœê·¼ 1ë…„
    'd': '5y',    # ì¼ë´‰ì€ 5ë…„
    'w': '10y',   # ì£¼ë´‰ì€ 10ë…„
    'mon': '10y', # ì›”ë´‰ì€ 10ë…„ (RS ê³„ì‚°ì— í•„ìˆ˜)
}
# ---------------------------------------------

DEFAULT_ARGS = {
    'owner': 'tradesmart_ai',
    'retries': 1,  # ì´ˆê¸° ì ì¬ëŠ” ì¬ì‹œë„ ìµœì†Œí™”
    'retry_delay': pendulum.duration(minutes=5),  # ì¬ì‹œë„ ê°„ 5ë¶„ ëŒ€ê¸°
}

# dags/dag_initial_loader.py

def _run_stock_info_load_task(**kwargs):
    """
    (í†µí•© ë¡œì§) ì™¸ë¶€ APIì™€ DBì˜ ì „ì²´ ì¢…ëª© ë§ˆìŠ¤í„°ë¥¼ ë™ê¸°í™”í•©ë‹ˆë‹¤.
    dag_daily_batchì™€ ë™ì¼í•œ í‘œì¤€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ì •ì±…ì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    import logging
    from src.database import SessionLocal
    # sync_stock_master_to_dbë¥¼ ì§ì ‘ ì„í¬íŠ¸í•˜ì—¬ ì‚¬ìš©
    from src.master_data_manager import sync_stock_master_to_db

    logger = logging.getLogger(__name__)
    logger.info("í‘œì¤€ ë™ê¸°í™” í•¨ìˆ˜(sync_stock_master_to_db)ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¢…ëª© ë§ˆìŠ¤í„°ë¥¼ ë™ê¸°í™”í•©ë‹ˆë‹¤.")

    db_session = SessionLocal()
    try:
        # ì´ TaskëŠ” DB ìƒíƒœë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ëª©ì ì´ë¯€ë¡œ, ë°˜í™˜ê°’ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        sync_stock_master_to_db(db_session)
        logger.info("ì¢…ëª© ë§ˆìŠ¤í„° ë™ê¸°í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì¢…ëª© ë§ˆìŠ¤í„° ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise
    finally:
        db_session.close()


def _calculate_default_target_datetime() -> str:
    """
    LIVE ëª¨ë“œì˜ target_datetime ê¸°ë³¸ê°’ì„ ë™ì ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ì¥ ë§ˆê° í›„: ì˜¤ëŠ˜ ë‚ ì§œì˜ 16:00
    - ì¥ ì¤‘/ì „: ì§ì „ ê±°ë˜ì¼ì˜ 16:00
    """
    kst = ZoneInfo('Asia/Seoul')
    now_kst = datetime.now(kst)
    trading_end_time = dt_time(15, 30)

    target_date = now_kst.date()

    # ì¥ ë§ˆê° ì‹œê°„ ì´ì „ì´ë©´, ë‚ ì§œë¥¼ í•˜ë£¨ ì „ìœ¼ë¡œ ì„¤ì •
    if now_kst.time() < trading_end_time:
        target_date -= timedelta(days=1)

    # ì£¼ë§ ì²˜ë¦¬: í† ìš”ì¼(5)ì´ë©´ ê¸ˆìš”ì¼ë¡œ, ì¼ìš”ì¼(6)ì´ë©´ ê¸ˆìš”ì¼ë¡œ ì´ë™
    if target_date.weekday() == 5:  # Saturday
        target_date -= timedelta(days=1)
    elif target_date.weekday() == 6:  # Sunday
        target_date -= timedelta(days=2)

    # ìµœì¢… ê¸°ì¤€ ì‹œì ì„ ì˜¤í›„ 4ì‹œë¡œ ì„¤ì •
    default_dt = datetime.combine(target_date, dt_time(16, 0), tzinfo=kst)
    return default_dt.strftime('%Y-%m-%d %H:%M:%S')


def _determine_target_stocks_task(**kwargs):
    """
    ì´ˆê¸° ì ì¬ ëŒ€ìƒì„ ê²°ì •í•˜ê³  'ì œë¡œ í•„í„°'ë¥¼ ì ìš©í•˜ì—¬ XComìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    """
    from src.master_data_manager import get_filtered_initial_load_targets

    config = kwargs.get('dag_run').conf if kwargs.get('dag_run') else {}
    test_stock_codes_param = config.get('test_stock_codes')

    db_session = SessionLocal()
    try:
        # ìˆ˜ì • ì œì•ˆ: ìˆ˜ë™ ëª¨ë“œì—ì„œë„ ì œë¡œ í•„í„°ë§ ì ìš©
        if test_stock_codes_param:
            user_codes = [code.strip() for code in test_stock_codes_param.split(',') if code.strip()]
            # âœ… get_filtered_initial_load_targetsì— ì‚¬ìš©ì ì§€ì • ì¢…ëª© ì „ë‹¬
            target_codes = get_filtered_initial_load_targets(db_session, user_codes)
            logging.info(f"ì‚¬ìš©ì ì§€ì • ì¢…ëª© {len(user_codes)}ê°œ ì¤‘ {len(target_codes)}ê°œê°€ í•„í„°ë§ í›„ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        else:
            # ìë™ ëª¨ë“œ: DB ì¡°íšŒ ë° ì œë¡œ í•„í„° ì ìš©
            target_codes = get_filtered_initial_load_targets(db_session)
            logging.info(f"ìë™ í•„í„°ë§ëœ ìµœì¢… ëŒ€ìƒ ì¢…ëª©: {len(target_codes)}ê°œ")

        return target_codes
    finally:
        db_session.close()


def _run_initial_load_task(db_session=None, **kwargs):
    """
    íŒŒë¼ë¯¸í„°ë¥¼ ì½ì–´ LIVE ëª¨ë“œì—ì„œëŠ” ì´ˆê¸° ì ì¬ë¥¼,
    SIMULATION ëª¨ë“œì—ì„œëŠ” DB ìŠ¤ëƒ…ìƒ· ìƒì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    config = kwargs.get('dag_run').conf if kwargs.get('dag_run') else {}
    execution_mode = config.get('execution_mode', 'LIVE')
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸ¯ _run_initial_load_task ì‹œì‘: mode={execution_mode}")

    # 1. 'target_datetime' ê²°ì • (ì§€ëŠ¥í˜• ê¸°ë³¸ê°’ ë¡œì§ ì¶”ê°€)
    target_datetime_str = config.get('target_datetime')
    if not target_datetime_str and execution_mode == 'LIVE':
        target_datetime_str = _calculate_default_target_datetime()
        logger.info(f"LIVE ëª¨ë“œì—ì„œ ê¸°ì¤€ ì‹œì ì´ ì§€ì •ë˜ì§€ ì•Šì•„, '{target_datetime_str}'ë¡œ ìë™ ì„¤ì •í•©ë‹ˆë‹¤.")

    # --- DB Session Management ---
    session_owner = False
    if execution_mode != 'SIMULATION':
        if db_session is None:
            db_session = SessionLocal()
            session_owner = True

    try:
        if execution_mode == 'SIMULATION':
            # --- SIMULATION ëª¨ë“œ: ë°ì´í„° ìŠ¤ëƒ…ìƒ· ì¤€ë¹„ ---

            test_stock_codes_str = config.get('test_stock_codes', '')
            target_datetime_str = config.get('target_datetime')

            if not test_stock_codes_str or not target_datetime_str:
                raise AirflowException(
                    "SIMULATION ëª¨ë“œì—ì„œëŠ” 'test_stock_codes'ì™€ 'target_datetime' íŒŒë¼ë¯¸í„°ê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤."
                )

            user_stock_codes = [code.strip() for code in test_stock_codes_str.split(',') if code.strip()]

            # 1. [ì‹ ê·œ] RS ê³„ì‚°ì— í•„ìš”í•œ ëª¨ë“  ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
            db = SessionLocal()
            try:
                # [ë³€ê²½] ëª¨ë“  ì—…ì¢… ëŒ€ì‹  í•„ìš”í•œ ì—…ì¢…ë§Œ ì¡°íšŒ
                from src.utils.sector_mapper import get_necessary_sector_codes
                user_sector_codes = get_necessary_sector_codes(db, user_stock_codes)
                market_index_codes = {'001', '101'}
                all_necessary_codes = list(set(user_stock_codes) | user_sector_codes | market_index_codes)
                logger.info(f"RS ê³„ì‚° ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {len(all_necessary_codes)}ê°œ ê´€ë ¨ ì½”ë“œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            finally:
                db.close()

            # 2. ë°ì´í„° ìŠ¤ëƒ…ìƒ· ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ (í†µí•©ëœ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)
            snapshot_result = create_simulation_snapshot(
                stock_codes=all_necessary_codes,
                execution_time=target_datetime_str
            )

            if snapshot_result.get('status') != 'completed':
                raise AirflowException(f"âŒ SIMULATION ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹¤íŒ¨: {snapshot_result.get('error')}")

            # 3. Airflow Variable ì €ì¥ (ì‚¬ìš©ì ì…ë ¥ ì¢…ëª© ê¸°ì¤€)
            snapshot_meta = {
                "snapshot_time": target_datetime_str,
                "stock_codes": user_stock_codes, # Variableì—ëŠ” ì‚¬ìš©ìê°€ ëª…ì‹œí•œ ì¢…ëª©ë§Œ ê¸°ë¡
                "timeframes": snapshot_result["timeframes"],
                "prepared_at": datetime.now().isoformat(),
                "total_rows": snapshot_result["total_rows"],
                "status": snapshot_result["status"]
            }
            Variable.set("simulation_snapshot_info", json.dumps(snapshot_meta))
            logger.info(f"âœ… SIMULATION ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ: {target_datetime_str} ({snapshot_result['total_rows']}í–‰)")
            return

        else:
            # --- LIVE ëª¨ë“œ: ê¸°ì¡´ ì´ˆê¸° ì ì¬ ë¡œì§ (ìˆ˜ì •) ---
            logger.info("Starting LIVE mode initial loading process.")

            # 'target_datetime'ì„ 'base_date' (YYYYMMDD) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            base_date = None
            if target_datetime_str:
                try:
                    base_date = datetime.strptime(target_datetime_str, '%Y-%m-%d %H:%M:%S').strftime('%Y%m%d')
                except ValueError:
                    raise AirflowException(f"target_datetime í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'YYYY-MM-DD HH:MM:SS' í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")

            # --- LIVE ëª¨ë“œ: ëŒ€ìƒ ì„ ì • ë¡œì§ì„ XCom PULLë¡œ ëŒ€ì²´ ---
            logger.info("LIVE ëª¨ë“œ: XComì—ì„œ ëŒ€ìƒ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            ti = kwargs['ti']
            target_stocks = ti.xcom_pull(task_ids='determine_target_stocks_task')

            if not target_stocks:
                print("ì²˜ë¦¬í•  ëŒ€ìƒ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return

            # [ê¸°ì¡´ ë¡œì§ ìœ ì§€] ê³µí†µ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            timeframes_to_process = config.get('timeframes', ['5m', '30m', '1h', 'd', 'w', 'mon'])

            # 3. ì‘ì—… ì‹¤í–‰ ë¡œì§
            print(f'\n{'='*60}')
            print(f'ğŸš€ LIVE ëª¨ë“œë¡œ ì´ˆê¸° ì ì¬ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.')
            print(f'ğŸ“Š ëŒ€ìƒ ì¢…ëª© ìˆ˜: {len(target_stocks)}ê°œ')
            print(f'â° íƒ€ì„í”„ë ˆì„: {timeframes_to_process}')
            print(f'ğŸ“… ê¸°ì¤€ ì‹œì : {target_datetime_str or 'ìë™ ê³„ì‚°ë¨'}')
            print(f'ğŸ“† ê¸°ê°„: íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™”ëœ ê¸°ê°„ ì‚¬ìš©')
            print(f'ğŸ”§ ì‹¤í–‰ ëª¨ë“œ: {execution_mode}')
            print(f'{'='*60}\n')

            success_count = 0
            fail_count = 0
            total_tasks = len(target_stocks) * len(timeframes_to_process)
            current_task = 0

            logger = logging.getLogger(__name__)
            logger.info("ì—…ì¢… ë§ˆìŠ¤í„° ë°ì´í„° ì¤€ë¹„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            all_sectors = get_sector_list()
            if all_sectors:
                stmt = insert(Sector).values(all_sectors)
                update_stmt = stmt.on_conflict_do_update(
                    index_elements=['sector_code'],
                    set_={'sector_name': stmt.excluded.sector_name, 'market_name': stmt.excluded.market_name}
                )
                db_session.execute(update_stmt)
                db_session.commit()
                logger.info(f"{len(all_sectors)}ê°œ ì—…ì¢… ë§ˆìŠ¤í„° ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.")
            else:
                logger.warning("APIë¡œë¶€í„° ì—…ì¢… ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # --- [ìˆ˜ì •] ê¸°ì¤€ ë°ì´í„°(ì§€ìˆ˜, ì—…ì¢…) ì ì¬ ë¡œì§ ---
            logger.info("ê¸°ì¤€ ë°ì´í„°(ì§€ìˆ˜, ì—…ì¢…)ì˜ ê³¼ê±° ì¼/ì£¼/ì›”ë´‰ ì ì¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            index_codes = ['001', '101']

            # [í•µì‹¬ ìˆ˜ì •] target_stocks (XComìœ¼ë¡œ ë°›ì€ ìµœì¢… ëŒ€ìƒ) ìœ ë¬´ì— ë”°ë¼ ë¶„ê¸°
            if target_stocks:
                # ìˆ˜ë™ ëª¨ë“œ(test_stock_codes ì§€ì •)ë¡œ ì‹¤í–‰ëœ ê²½ìš°, í•´ë‹¹ ì¢…ëª©ì˜ ì—…ì¢…ë§Œ ì¡°íšŒ
                from src.utils.sector_mapper import get_necessary_sector_codes
                sector_codes = list(get_necessary_sector_codes(db_session, target_stocks))
                logger.info(f"LIVE(ìˆ˜ë™ ëª¨ë“œ): ì§€ì •ëœ ì¢…ëª©ê³¼ ê´€ë ¨ëœ {len(sector_codes)}ê°œ ì—…ì¢… ë°ì´í„°ë§Œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            else:
                # ìë™ ëª¨ë“œ(test_stock_codes ë¯¸ì§€ì •)ì¸ ê²½ìš°, ì „ì²´ ì—…ì¢… ì¡°íšŒ
                sector_codes = [s.sector_code for s in db_session.query(Sector.sector_code).all()]
                logger.info(f"LIVE(ìë™ ëª¨ë“œ): ì „ì²´ {len(sector_codes)}ê°œ ì—…ì¢… ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

            baseline_codes = index_codes + sector_codes

            # ê¸°ì¤€ ë°ì´í„° ë ˆì½”ë“œê°€ stocks í…Œì´ë¸”ì— ì¡´ì¬í•˜ë„ë¡ ë³´ì¥
            baseline_stock_info = [{'stock_code': code, 'stock_name': 'BASELINE_DATA', 'is_active': True, 'backfill_needed': False} for code in baseline_codes]
            stmt = insert(Stock).values(baseline_stock_info)
            db_session.execute(stmt.on_conflict_do_nothing(index_elements=['stock_code']))
            db_session.commit()

            # ì²˜ë¦¬í•  íƒ€ì„í”„ë ˆì„ ëª©ë¡ ì •ì˜
            baseline_timeframes = ['d', 'w', 'mon']

            # [ê°œì„ ] ì—ëŸ¬ ì¹´ìš´íŒ…ì„ í†µí•œ ì•ˆì •ì„± í™•ë³´
            error_count = 0
            total_baseline_tasks = len(baseline_codes) * len(baseline_timeframes)

            for code in baseline_codes:
                for timeframe in baseline_timeframes:
                    try:
                        # [ê°œì„ ] TIMEFRAME_PERIOD_MAP ë³€ìˆ˜ì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë°©ì–´ì  ì½”ë“œ
                        if 'TIMEFRAME_PERIOD_MAP' in globals():
                            period = TIMEFRAME_PERIOD_MAP.get(timeframe, '10y')
                        else:
                            # TIMEFRAME_PERIOD_MAPì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜
                            period = '10y' if timeframe == 'mon' else '5y'

                        load_initial_history(
                            stock_code=code,
                            timeframe=timeframe,
                            period=period,
                            execution_mode=execution_mode
                        )
                        # [ê°œì„ ] API Rate Limiting ê°•í™”
                        time.sleep(0.5)
                    except Exception as e:
                        error_count += 1
                        # [ê°œì„ ] ì—ëŸ¬ ë¡œê·¸ì— timeframe ì •ë³´ ì¶”ê°€
                        logger.error(f"ê¸°ì¤€ ë°ì´í„° ì ì¬ ì¤‘ ì˜¤ë¥˜: {code} ({timeframe}) - {e}", exc_info=True)
                        continue

            # [ê°œì„ ] ì—ëŸ¬ìœ¨ì´ 30%ë¥¼ ì´ˆê³¼í•˜ë©´ DAG ì‹¤íŒ¨ ì²˜ë¦¬
            if total_baseline_tasks > 0 and (error_count / total_baseline_tasks) > 0.3:
                raise AirflowException(f"ë„ˆë¬´ ë§ì€ ê¸°ì¤€ ë°ì´í„° ì ì¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì´ {total_baseline_tasks}ê°œ ì¤‘ {error_count}ê°œ ì‹¤íŒ¨)")

            logger.info("ê¸°ì¤€ ë°ì´í„° ê³¼ê±° ì¼/ì£¼/ì›”ë´‰ ì ì¬ ì™„ë£Œ.")

            for stock_code in target_stocks:
                all_success = True
                for timeframe in timeframes_to_process:
                    current_task += 1
                    # íƒ€ì„í”„ë ˆì„ë³„ ìµœì í™”ëœ ê¸°ê°„ ì¡°íšŒ
                    period_for_timeframe = TIMEFRAME_PERIOD_MAP.get(timeframe, '1y')
                    print(f"\n[{current_task}/{total_tasks}] ì²˜ë¦¬ ì¤‘: {stock_code} - {timeframe} (ê¸°ê°„: {period_for_timeframe})")
                    try:
                        success = load_initial_history(
                            stock_code=stock_code, timeframe=timeframe, base_date=base_date, period=period_for_timeframe, execution_mode=execution_mode
                        )
                        if success:
                            success_count += 1
                            print(f"âœ… ì„±ê³µ: {stock_code} - {timeframe}")
                        else:
                            fail_count += 1
                            all_success = False
                            print(f"âš ï¸ ë°ì´í„° ì—†ìŒ:{stock_code} - {timeframe}")
                    except Exception as e:
                        fail_count += 1
                        all_success = False
                        print(f"âŒ ì‹¤íŒ¨: {stock_code} - {timeframe}: {str(e)}")
                    time.sleep(0.3) # API ì„œë²„ ë³´í˜¸
                
                if all_success:
                    db_session.query(Stock).filter(Stock.stock_code == stock_code).update({"backfill_needed": False})
                    db_session.commit()
                    print(f"'{stock_code}' ë°±í•„ ì™„ë£Œ. backfill_needed=Falseë¡œ ì—…ë°ì´íŠ¸.")

            # --- [ì‹ ê·œ ìµœì¢… ë‹¨ê³„] 4. ì ì¬ëœ ì¢…ëª©ì— ëŒ€í•œ ì—…ì¢… ì½”ë“œ ë°±í•„ ---
            try:
                from src.master_data_manager import backfill_sector_codes
                logger.info("ì´ˆê¸° ì ì¬ëœ ì¢…ëª©ì— ëŒ€í•œ ì—…ì¢… ì½”ë“œ ë§¤í•‘(ë°±í•„)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                backfill_sector_codes()
                logger.info("ì—…ì¢… ì½”ë“œ ë§¤í•‘(ë°±í•„) ì™„ë£Œ.")
            except Exception as e:
                logger.error(f"ì´ˆê¸° ì ì¬ í›„ ì—…ì¢… ì½”ë“œ ë°±í•„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

            # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ì´í•˜ ìƒëµ)

    finally:
        if execution_mode != 'SIMULATION' and session_owner:
            db_session.close()

    # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ì´ˆê¸° ì ì¬ ì™„ë£Œ")
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨/ë°ì´í„° ì—†ìŒ: {fail_count}ê°œ")
    print(f"ğŸ“Š ì „ì²´: {total_tasks}ê°œ")
    print(f"{'='*60}\n")

    if fail_count > total_tasks * 0.3:
        raise AirflowException(f"ë„ˆë¬´ ë§ì€ ì‘ì—…({fail_count}/{total_tasks})ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# DAG ì •ì˜
with DAG(
    dag_id='dag_initial_loader',
    default_args=DEFAULT_ARGS,
    schedule_interval=None,  # ìˆ˜ë™ ì‹¤í–‰ ì „ìš© (ë§¤ìš° ì¤‘ìš”!)
    start_date=pendulum.datetime(2025, 7, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=['Utility', 'Backfill', 'Manual'],
    description='[ìœ í‹¸ë¦¬í‹°] ê³¼ê±° ë°ì´í„° ëŒ€ëŸ‰ ì ì¬ (ì´ˆê¸° êµ¬ì¶• ë° ë°ì´í„° ë°±í•„ìš©)',
    params={
        "test_stock_codes": Param(
            type=["null", "string"],
            default=None,
            title="[í…ŒìŠ¤íŠ¸ìš©] íŠ¹ì • ì¢…ëª© ëŒ€ìƒ ì‹¤í–‰",
            description="ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì—¬ëŸ¬ ì¢…ëª©ì€ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. (ì˜ˆ: 005930,000660)"
        ),
        "stock_limit": Param(
            type="integer",
            default=0,
            title="ì¢…ëª© ìˆ˜ ì œí•œ (0=ì œí•œ ì—†ìŒ)",
            description="í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ ì²˜ë¦¬í•  ì¢…ëª© ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤. 0 ë˜ëŠ” ìŒìˆ˜ì´ë©´ í•„í„°ë§ëœ ì „ì²´ ì¢…ëª©ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."
        ),
        "timeframes": Param(
            type=["null", "array"],
            default=['5m', '30m', '1h', 'd', 'w', 'mon'],
            title="íƒ€ì„í”„ë ˆì„ ëª©ë¡",
            description="ìˆ˜ì§‘í•  íƒ€ì„í”„ë ˆì„ ëª©ë¡ì„ ì§€ì •í•©ë‹ˆë‹¤. ë¹„ì›Œë‘ë©´ ê¸°ë³¸ 6ê°œ íƒ€ì„í”„ë ˆì„(5m, 30m, 1h, d, w, mon)ì„ ëª¨ë‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        ),
        "execution_mode": Param(
            type="string",
            default="LIVE",
            title="ì‹¤í–‰ ëª¨ë“œ",
            description="LIVE: APIë¡œ ì´ˆê¸° ì ì¬, SIMULATION: DB ìŠ¤ëƒ…ìƒ· ìƒì„±",
            enum=["LIVE", "SIMULATION"]
        ),
        "target_datetime": Param(
            type=["null", "string"],
            default="",
            title="ê¸°ì¤€ ì‹œì  (YYYY-MM-DD HH:MM:SS)",
            description="[LIVE ëª¨ë“œ] ì´ˆê¸° ì ì¬ì˜ ì¢…ë£Œ ì‹œì . ë¹„ì›Œë‘ë©´ ê°€ì¥ ìµœê·¼ ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤. [SIMULATION ëª¨ë“œ] ìŠ¤ëƒ…ìƒ· ìƒì„±ì˜ ê¸°ì¤€ ì‹œì  (í•„ìˆ˜ ì…ë ¥)."
        )
    },
    doc_md="""
    ### [ìœ í‹¸ë¦¬í‹°] ê³¼ê±° ë°ì´í„° ëŒ€ëŸ‰ ì ì¬ DAG

    ì´ DAGëŠ” ì‹œìŠ¤í…œì„ ìµœì´ˆë¡œ êµ¬ì¶•í•˜ê±°ë‚˜, íŠ¹ì • ì¢…ëª©ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë³´ê°•(ë°±í•„)í•´ì•¼ í•  ë•Œ **ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰**í•˜ëŠ” ê´€ë¦¬ìš© ë„êµ¬ì…ë‹ˆë‹¤.

    #### ì‹¤í–‰ ëª¨ë“œ
    - **ìë™ ëª¨ë“œ (ê¸°ë³¸)**: `test_stock_codes` íŒŒë¼ë¯¸í„°ë¥¼ ë¹„ì›Œë‘ê³  ì‹¤í–‰í•˜ë©´, DBì—ì„œ `backfill_needed=True`ë¡œ í‘œì‹œëœ ëª¨ë“  ì¢…ëª©ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ê³¼ê±° ë°ì´í„°ë¥¼ ì ì¬í•©ë‹ˆë‹¤.
    - **ìˆ˜ë™ ëª¨ë“œ**: `test_stock_codes`ì— ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ì—¬ íŠ¹ì • ì¢…ëª©ì˜ ê³¼ê±° ë°ì´í„°ë§Œ ì„ ë³„ì ìœ¼ë¡œ ì ì¬í•©ë‹ˆë‹¤. ì‹ ê·œ ê´€ì‹¬ ì¢…ëª© ì¶”ê°€ë‚˜ ë°ì´í„° ìœ ì‹¤ ì‹œ ë³µêµ¬ ìš©ë„ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    **ì£¼ì˜**: ì´ DAGëŠ” ëŒ€ëŸ‰ì˜ API í˜¸ì¶œì„ ìœ ë°œí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    """
) as dag:
    
    # ë‹¨ì¼ Task: ì¢…ëª© ì •ë³´ ì ì¬
    stock_info_load_task = PythonOperator(
        task_id='stock_info_load_task',
        python_callable=_run_stock_info_load_task,
        provide_context=True,
        # Pool ì œê±°: ì¢…ëª© ì •ë³´ ì ì¬ëŠ” API í˜¸ì¶œì´ ì•„ë‹ˆë¯€ë¡œ Pool ë¶ˆí•„ìš”
        doc_md="""
        ### ì¢…ëª© ì •ë³´ ì ì¬ Task
        
        ì´ TaskëŠ” ì¢…ëª© ì •ë³´ë¥¼ DBì— ì ì¬í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.
        ì´ëŠ” ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ì˜ ì „ì œì¡°ê±´ì´ë©°, ëŒ€ëŸ‰ ë°ì´í„° ì ì¬ ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        
        **ì£¼ì˜**: ì´ TaskëŠ” ëŒ€ëŸ‰ ë°ì´í„° ì ì¬ ì‘ì—…ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ ì™„ë£Œë©ë‹ˆë‹¤.
        """
    )
    
    # ëŒ€ìƒ ì¢…ëª© ì„ ì • Task ì¶”ê°€
    determine_target_stocks_task = PythonOperator(
        task_id='determine_target_stocks_task',
        python_callable=_determine_target_stocks_task,
        doc_md="""
        ### ëŒ€ìƒ ì¢…ëª© ì„ ì • ë° í•„í„°ë§ Task
        - **ìë™ ëª¨ë“œ**: `backfill_needed=True`ì¸ ì¢…ëª©ì„ ì¡°íšŒí•˜ì—¬ 'ì œë¡œ í•„í„°'ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        - **ìˆ˜ë™ ëª¨ë“œ**: `test_stock_codes` íŒŒë¼ë¯¸í„°ë¡œ ì§€ì •ëœ ì¢…ëª©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        - **ì¶œë ¥**: ìµœì¢… ëŒ€ìƒ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ XComìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
        """
    )
    
    # ë‹¨ì¼ Task: ì´ˆê¸° ë°ì´í„° ì ì¬
    initial_load_task = PythonOperator(
        task_id='initial_load_task',
        python_callable=_run_initial_load_task,
        provide_context=True,
        # Pool ì œê±°: ìˆœì°¨ ì‹¤í–‰(for ë¬¸)ì´ë¯€ë¡œ Pool ë¶ˆí•„ìš”, ì¦ë¶„ ì—…ë°ì´íŠ¸ DAGì—ì„œ Pool ì‚¬ìš© ì˜ˆì •
        doc_md="""
        ### ì´ˆê¸° ë°ì´í„° ì ì¬ Task
        
        ì´ TaskëŠ” ì „ë‹¬ëœ íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ì„¸ ê°€ì§€ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤:
        
        **1. ì¼ê´„ ì‘ì—… ëª¨ë“œ (run_all_targets=true)**
        - 30ê°œ íƒ€ê²Ÿ ì¢…ëª© Ã— 5ê°œ íƒ€ì„í”„ë ˆì„ = ì´ 150ê°œ ì‘ì—… ìˆ˜í–‰
        - ê° ì‘ì—… ì‚¬ì´ì— 0.3ì´ˆ ëŒ€ê¸° (ìˆœì°¨ ì‹¤í–‰ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ Rate Limiting)
        - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 1ì‹œê°„
        
        **2. íŠ¹ì • ì¢…ëª© ì „ì²´ ëª¨ë“œ (stock_codeë§Œ ì§€ì •)**
        - 1ê°œ ì¢…ëª© Ã— 5ê°œ íƒ€ì„í”„ë ˆì„ = ì´ 5ê°œ ì‘ì—… ìˆ˜í–‰
        - ê° ì‘ì—… ì‚¬ì´ì— 0.3ì´ˆ ëŒ€ê¸°
        
        **3. ë‹¨ì¼ ì‘ì—… ëª¨ë“œ (stock_code + timeframe ì§€ì •)**
        - 1ê°œ ì¢…ëª© Ã— 1ê°œ íƒ€ì„í”„ë ˆì„ = 1ê°œ ì‘ì—… ìˆ˜í–‰
        
        **ê³µí†µ ê¸°ëŠ¥:**
        - íŒŒë¼ë¯¸í„° ê²€ì¦
        - load_initial_history í•¨ìˆ˜ í˜¸ì¶œ
        - ì§„í–‰ ìƒí™© ë° ê²°ê³¼ ë¡œê¹…
        - ì‹¤íŒ¨ìœ¨ì´ 30% ì´ˆê³¼ ì‹œ DAG ì‹¤íŒ¨ ì²˜ë¦¬
        
        **Pool ì‚¬ìš© ì•ˆ í•¨**: ìˆœì°¨ ì‹¤í–‰ì´ë¯€ë¡œ Pool ë¶ˆí•„ìš” (ì¦ë¶„ ì—…ë°ì´íŠ¸ DAGì—ì„œ Pool ì‚¬ìš© ì˜ˆì •)
        """
    )
    
    # ìµœì¢… ì˜ì¡´ì„± ì„¤ì •
    stock_info_load_task >> determine_target_stocks_task >> initial_load_task 