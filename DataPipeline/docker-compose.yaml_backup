
# TradeSmartAI 프로젝트를 위한 Docker Compose 구성 파일
# - Airflow로 주식 데이터 수집 워크플로우 자동화
# - PostgreSQL로 tradesmart_db(주식 데이터)와 airflow_meta(Airflow 메타데이터) 저장
# - LocalExecutor 사용: 소규모~중규모 프로젝트에 적합, Redis/워커 불필요
# - GCP 배포 호환: Cloud Composer(KubernetesExecutor), Cloud SQL, Cloud Run
# - webapp은 아직 계획 미구체화로 주석 처리
#
# 참고:
# - 프로젝트 폴더: /mnt/c/Users/jscho/airflow (WSL2)
# - README.md 기반: tradesmart_db, kiwoom_api, Airflow DAG
#
# 사용 방법:
# 1. .env 파일 설정 (POSTGRES_*, KIWOOM_* 변수)
# 2. docker-compose up -d 실행
# 3. Airflow UI: http://localhost:8080 (ID: airflow, PW: airflow)
# 4. DB 확인: psql -h localhost -p 5433 -U tradesmart_user -d tradesmart_db
#
# 리마크:
# - webapp 서비스는 현재 계획이 구체화되지 않아 주석 처리됨.
# - 향후 FastAPI + Chart.js로 차트 구현 시 주석 해제 및 webapp 폴더 추가.
# - 예시 webapp 구성은 이전 대화의 main.py, Dockerfile, index.html 참조.
# - GCP 배포 시 webapp은 Cloud Run으로 배포 가능.

version: '3.8'

# 공통 Airflow 설정: 모든 Airflow 서비스(airflow-init, webserver, scheduler)에 적용
x-airflow-common:
  &airflow-common
  image: apache/airflow:2.10.5  # Airflow 2.10.5 사용 (안정적인 최신 버전)
  environment:
    # LocalExecutor: Redis/워커 없이 로컬에서 태스크 병렬 실행
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    # Airflow 메타데이터 DB 연결 (postgres-airflow의 airflow_meta)
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres-airflow:5432/airflow_meta

    PYTHONPATH: /opt/airflow

    AIRFLOW__CORE__HOSTNAME_CALLABLE: "socket:gethostname"
    AIRFLOW__LOGGING__WORKER_LOG_SERVER_HOST: airflow-scheduler
    # --- 아래 4줄을 추가하여 Task가 DB 정보를 알 수 있도록 합니다 ---
    POSTGRES_HOST: postgres-tradesmart
    POSTGRES_USER: ${POSTGRES_TRADESMART_USER}
    POSTGRES_PASSWORD: ${POSTGRES_TRADESMART_PASSWORD}
    POSTGRES_DB: tradesmart_db
    # ----------------------------------------------------

    # 타임존 설정: UI와 로그에서 한국 시간으로 표시
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Seoul
    AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: Asia/Seoul
    # 추가 타임존 설정
    AIRFLOW__CORE__TIMEZONE: Asia/Seoul
    TZ: Asia/Seoul
    
    # DAG 생성 시 기본 일시중지
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    # Airflow 예제 DAG 비활성화
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    # 스케줄러 Healthcheck 웹 서버 활성화
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # Trigger DAG w/ Config 버튼 활성화 (Airflow 2.7.0+)
    AIRFLOW__WEBSERVER__SHOW_TRIGGER_FORM_IF_NO_PARAMS: 'true'
  volumes:
    # 로컬 폴더를 Airflow 컨테이너에 마운트
    - ./dags:/opt/airflow/dags        # DAG 정의
    - ./logs:/opt/airflow/logs        # 로그 저장
    - ./config:/opt/airflow/config    # Airflow 설정
    - ./plugins:/opt/airflow/plugins  # 커스텀 플러그인
    - ./src:/opt/airflow/src          # 키움증권 API, DB 모델 등 소스 코드
    - ./data:/opt/airflow/data
  user: "${AIRFLOW_UID}:${AIRFLOW_GID}"     # Airflow UID 설정 (파일 권한 문제 방지)
  depends_on:
    postgres-airflow:
      condition: service_healthy      # Airflow DB 준비 완료 시 실행
  networks:
    - tradesmart-network             # 컨테이너 간 통신 네트워크

services:
  # Airflow 메타데이터를 위한 PostgreSQL
  postgres-airflow:
    image: postgres:15  # PostgreSQL 15 사용 (README)
    environment:
      POSTGRES_USER: ${POSTGRES_AIRFLOW_USER}      # .env: airflow_user
      POSTGRES_PASSWORD: ${POSTGRES_AIRFLOW_PASSWORD} # airflow_secure_123
      POSTGRES_DB: airflow_meta                    # Airflow 메타데이터 DB
    volumes:
      - postgres-airflow-volume:/var/lib/postgresql/data  # 데이터 영속 저장
    ports:
      - "5432:5432"  # 호스트에서 5432로 접근 (DBeaver 등)
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_AIRFLOW_USER}"]
      interval: 30s
      retries: 5
      start_period: 5s
    restart: always
    networks:
      - tradesmart-network

  # 주식 데이터를 위한 PostgreSQL (tradesmart_db)
  postgres-tradesmart:
    image: postgres:15
    environment:
      POSTGRES_USER: ${POSTGRES_TRADESMART_USER}      # .env: tradesmart_user
      POSTGRES_PASSWORD: ${POSTGRES_TRADESMART_PASSWORD} # tradesmart_secure_456
      POSTGRES_DB: tradesmart_db                     # 주식 데이터 DB
    volumes:
      - postgres-tradesmart-volume:/var/lib/postgresql/data
    ports:
      - "5433:5432"  # 호스트에서 5433으로 접근 (5432와 충돌 방지)
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_TRADESMART_USER}"]
      interval: 30s
      retries: 5
      start_period: 5s
    restart: always
    networks:
      - tradesmart-network

  # Airflow 초기화: DB 설정 및 관리자 계정 생성
  airflow-init:
    image: apache/airflow:2.10.5
    #entrypoint: /bin/bash
    command:
      - bash
      - -cx
      - |
        echo "Running DB Migrations for Airflow..."
        airflow db migrate && \
        echo "Creating tables for TradeSmartAI..."
        python /opt/airflow/src/database.py && \
        echo "Creating Airflow admin user..."
        airflow users create \
          --username $${_AIRFLOW_WWW_USER_USERNAME:-airflow} \
          --firstname Airflow \
          --lastname Admin \
          --role Admin \
          --email admin@example.com \
          --password $${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres-airflow:5432/airflow_meta
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}

      POSTGRES_HOST: postgres-tradesmart
      POSTGRES_DB: tradesmart_db
      POSTGRES_USER: ${POSTGRES_TRADESMART_USER}
      POSTGRES_PASSWORD: ${POSTGRES_TRADESMART_PASSWORD}

    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./config:/opt/airflow/config
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
    depends_on:
      postgres-airflow:
        condition: service_healthy
    networks:
      - tradesmart-network
    restart: "no"  # 초기화는 한 번만 실행

  # Airflow 웹 UI 및 API 제공
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"  # http://localhost:8080으로 접근
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    networks:
      - tradesmart-network

  # Airflow 스케줄러: DAG 실행 관리
  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    networks:
      - tradesmart-network

  # 웹 서비스 (FastAPI): 현재 계획 미구체화로 주석 처리
  # 리마크:
  # - webapp은 tradesmart_db에서 데이터를 조회해 차트/분석 데이터를 제공할 예정.
  # - 구현 시 FastAPI + Chart.js 추천 (이전 대화의 main.py, index.html 참조).
  # - 활성화하려면:
  #   1. ./webapp 폴더 생성 (main.py, Dockerfile, templates/index.html)
  #   2. 아래 주석 해제
  #   3. docker-compose up -d 재실행
  # - GCP 배포 시 Cloud Run으로 배포 가능.
  #webapp:
  #  build:
  #    context: ./webapp
  #    dockerfile: Dockerfile
  #  environment:
  #    POSTGRES_HOST: postgres-tradesmart
  #    POSTGRES_USER: ${POSTGRES_TRADESMART_USER}
  #    POSTGRES_PASSWORD: ${POSTGRES_TRADESMART_PASSWORD}
  #    POSTGRES_DB: tradesmart_db
  #  ports:
  #    - "8000:8000"  # http://localhost:8000/stocks/chart
  #  depends_on:
  #    postgres-tradesmart:
  #      condition: service_healthy
  #  networks:
  #    - tradesmart-network
  #  restart: always

networks:
  tradesmart-network:
    driver: bridge

volumes:
  postgres-airflow-volume:
  postgres-tradesmart-volume:
